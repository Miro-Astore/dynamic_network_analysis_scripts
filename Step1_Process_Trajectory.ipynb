{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generalized Network Analysis Tutorial - Step 1\n",
    "\n",
    "The Network Analysis Tutorial is part of the work entitled **Generalized correlation-based dynamical network analysis: a new high-performance approach for identifying allosteric communications in molecular dynamics trajectories**, by Marcelo C. R. Melo, Rafael C. Bernardi, Cesar de la Fuente-Nunez, and Zaida Luthey-Schulten. For more information see http://faculty.scs.illinois.edu/schulten/. \n",
    "\n",
    "In this tutorial, we will use the Dynamic Network Analysis python package to explore the interactions between the OMP decarboxylase enzyme and its substrate, identifying clusters of amino acid residues that form domains, and active site residues that are important for binding and enzymatic activity.\n",
    "\n",
    "The tutorial is divided in two jupyter notebooks. In this notebook, **Step 1**, we will analyze the MD trajectory for the OMP decarboxylase system and generate the network data used for analysis. \n",
    "\n",
    "The trajectory files have approximately 500MB in size, and must be downloaded [from this link](http://www.ks.uiuc.edu/~rcbernardi/NetworkAnalysis/DynamicNetworkAnalysis_MDdata.tar.gz) and placed in the *TutorialData* folder.\n",
    "\n",
    "In the accompanying notebook, **Step 2**, we will load the data generated in the Step 1, and create analysis plots and visualizations of the network. \n",
    "\n",
    "In **Step 3**, which is outside of the jupyter notebook environment, we will produce high-quality renderings of the network using the popular visualization software VMD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-14T20:02:26.970833Z",
     "start_time": "2020-04-14T20:02:20.399680Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load the python package\n",
    "import os\n",
    "import dynetan\n",
    "from dynetan.toolkit import *\n",
    "from dynetan.viz import *\n",
    "from dynetan.proctraj import *\n",
    "from dynetan.gencor import *\n",
    "from dynetan.contact import *\n",
    "import argparse\n",
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the object that processes MD trajectories.\n",
    "dnap = DNAproc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "bPythonExport = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapResidueNames={'ALA':'A','CYS':'C','ASP':'D','GLU':'E','PHE':'F',\n",
    "                 'GLY':'G','HIS':'H','HSD':'H','HSE':'H','ILE':'I','LYS':'K','LEU':'L',\n",
    "                 'MET':'M','ASN':'N','PRO':'P','GLN':'Q','ARG':'R',\n",
    "                 'SER':'S','THR':'T','VAL':'V','TRP':'W','TYR':'Y',\n",
    "                 'MG':'Mg','POPC':'Popc',\n",
    "                 'ATP':'Atp','GTP':'Gtp',\n",
    "                 'NA':'Sod','SOD':'Sod','CLA':'Cl','CL':'Cl','POT':'Pot','K':'Pot',\n",
    "                 'SOL':'h2o','HOH':'h2o','WAT':'h2o','TIP':'h2o','H2O':'h2o',\n",
    "                }\n",
    "def name_node(dnap, node):\n",
    "    #i=dnap.nodesAtmSel[node].index\n",
    "    resname=dnap.nodesAtmSel[node].resname ; resid=dnap.nodesAtmSel[node].resid\n",
    "    return \"%s%s\" % (mapResidueNames[resname], resid)\n",
    "\n",
    "def clarify_duplicate_nodes(dictNames, dictSuffix):\n",
    "    \"\"\"\n",
    "    From two dicts with the same keys, add the respective suffix to all keys in the former that possess duplicate values.\n",
    "    \"\"\"\n",
    "    from itertools import chain\n",
    "    dictRev = {}\n",
    "    for k, v in dictNames.items():\n",
    "        dictRev.setdefault(v, set()).add(k)\n",
    "    setDuplicateKeys = set(chain.from_iterable( v for k, v in dictRev.items() if len(v) > 1))\n",
    "    \n",
    "    for k in setDuplicateKeys:\n",
    "        dictNames[k] = dictNames[k]+\"_\"+dictSuffix[k]\n",
    "    return dictNames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Node Groups\n",
    "\n",
    "In Network Analysis, each residue is represented by one or more \"nodes\", serving as proxies for groups of atoms form the original residue (Figure 1). This approach lowers computational cost and noise.\n",
    "\n",
    "For our purposes, we treat this as a coarse-graining procedure such that large molecules like ATP and POPC will gain multiple nodes to better distinguish between connections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# = = = Default workflow control parameters.\n",
    "bHasInterfaceDefinitions = False\n",
    "bIncludeSolvent = False\n",
    "segIDs = [] ; h2oName = []\n",
    "numSampledFrames = 100\n",
    "strideDCD = 0\n",
    "cutoffDist = 4.5 ; contactPersistence = 0.75\n",
    "numCoresAvailable=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if bPythonExport:\n",
    "    parser = argparse.ArgumentParser(description='Process trajactories for Dynamic Network Analysis.'\n",
    "                                                 'Equivalent to Step 1 of the tutorial without using Jupyter.',\n",
    "                                                 formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n",
    "    parser.add_argument('-o', '--output', type=str, dest='outputPrefix', default=None,\n",
    "                        help='Prefix used for all output files.')    \n",
    "    parser.add_argument('--top', type=str, dest='fileTopology', default='seg.psf',\n",
    "                        help='The name of a suitable file for MDAnalysis to generate a topology.')\n",
    "    parser.add_argument('fileTrajectories', type=str, metavar='N', nargs='+', default='sum.xtc',\n",
    "                        help='One or more trajectory files for MDAnalysis to read in. All frames are combined together.')\n",
    "    parser.add_argument('-n', '--num_windows', type=int, dest='numWinds', default=None,\n",
    "                        help='[Opt.] Split the total trajectory frames into N windows. By default equal to the number of files read.')\n",
    "    parser.add_argument('-f', '--num_frames', type=int, dest='numFrames', default=numSampledFrames,\n",
    "                        help='Number of frames to read for each window. Total number of frames will then be nWind*nFrames. '\n",
    "                       'This is computed by DNA as the total frames divided evenly.')\n",
    "    parser.add_argument('--dcd_stride', type=int, dest='strideDCD', default=strideDCD,\n",
    "                        help='The frame stride for the output dcd file, give to save disk space. Give 0 to save only the first and last frames.')\n",
    "#    = = = Very inconvenient to do within MDAnalysis. Outside design doc.\n",
    "#    parser.add_argument('--no_span', dest='bNoSpan', action='store_true',\n",
    "#                        help='When the number of frames is given, prevent windows from spanning across multiple trajectory files. '\n",
    "#                       'This will cause remainder frames to be discarded.')\n",
    "    parser.add_argument('--cpus', type=int, dest='nCPUs', default=numCoresAvailable,\n",
    "                            help='Set number of processes to enable partial parallelisation.')\n",
    "    #   =============== Analysis parameters\n",
    "    parser.add_argument('--segIDs', typr=str, dest='segIDs', default=None,\n",
    "                        help='A list of comma-separated segment IDs of components that should be included in network analysis. '\n",
    "                             'By default, will try to predict and include segIDs that are not water or named after simply ions. '\n",
    "                             'Note: The water segment is defined in the next argument.')\n",
    "    parser.add_argument('--segIDs_solv', typr=str, dest='segIDs_solv', default=None,\n",
    "                        help='Name of the water segment. A prediction will be attempted if not given '\n",
    "                             'by searching for possible names like SOL, HOH, TIP, WAT, H2O.')\n",
    "    parser.add_argument('--interfaceA', typr=str, dest='interfaceA', default=None,\n",
    "                        help='Definition of side-A of an interface to be analysed, using MDAnalysis selection syntax.')\n",
    "    parser.add_argument('--interfaceB', typr=str, dest='interfaceB', default=None,\n",
    "                        help='Definition of side-B of an interface to be analysed, using MDAnalysis selection syntax.')\n",
    "    parser.add_argument('--exclude_solvent', action='store_true', dest='bExcludeSolvent',\n",
    "                        help='Boolean to exclude potential solvent contacts in the analysis.')\n",
    "    parser.add_argument('--cutoff', type=float, dest='distCutoff', default=cutoffDist,\n",
    "                        help='Distance in Angstroms to consider two nodes as being in contact.'\n",
    "                             'Calculated as the nearest distance between all atoms of the node.')\n",
    "    parser.add_argument('--persistence', type=float, dest='ratioContactPersistence', default=contactPersistence,\n",
    "                        help='Minimum portion of frames for DNA to consider two nodes to be in sufficient contact,'\n",
    "                             'such that it will include this node pair as an edge in the output graph.')\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    numCoresAvailable=args.nCPUs\n",
    "\n",
    "    # = = = Analysis Configurations = = =\n",
    "    # Cutoff for contact map (In Angstroms)\n",
    "    cutoffDist = args.distCutoff\n",
    "    # Minimum contact persistance (In ratio of total trajectory frames)\n",
    "    contactPersistence = args.ratioContactPersistence\n",
    "    # Inclusion of solvent\n",
    "    bIncludeSolvent = not args.bExcludeSolvent\n",
    "\n",
    "    # = = = Optional interface definition. A dummy is other calculated.\n",
    "    if args.interfaceA is not None and args.interfaceB is not None:\n",
    "        bHasInterfaceDefinitions=True\n",
    "        seltextInterfaceA=args.interfaceA\n",
    "        seltextInterfaceB=args.interfaceB\n",
    "    \n",
    "    # = = Define selections of segments that will be included. = = \n",
    "    # = = Following the NAMD/VMD system, DynaNet uses a segment syntax instead of chain syntax to classify atoms.\n",
    "    #     Thus, segments will need to be defined in the topology file.\n",
    "    if args.segIDs is not None:\n",
    "        segIDs = args.segIDs.split(\",\")\n",
    "    if args.segIDs_solv is not None:\n",
    "        h2oName = args.segIDs_solv.split(\",\")\n",
    "    \n",
    "    topFile = args.fileTopology\n",
    "    trjFiles = args.fileTrajectories\n",
    "\n",
    "    if args.outputPrefix is None:\n",
    "        pathToData = \"./results\" % (allele, temperature)\n",
    "        fileNameRoot = \"analysis\"\n",
    "    else:\n",
    "        pathToData, fileNameRoot = os.path.split(args.outputPrefix)\n",
    "        \n",
    "    fullPathRoot = os.path.join(pathToData, fileNameRoot)\n",
    "\n",
    "    # Number of windows created from full simulation.\n",
    "    if args.numWinds is not None:\n",
    "        numWinds = args.numWinds\n",
    "    else:\n",
    "        numWinds = len(args.fileTrajectories)\n",
    "        \n",
    "    # Sampled frames per window\n",
    "    numSampledFrames = args.numFrames\n",
    "    \n",
    "    # Output\n",
    "    strideDCD = args.strideDCD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/d/ubuntu/projects/caspase-1\n"
     ]
    }
   ],
   "source": [
    "# = = = Change to the relevant work folder\n",
    "if not bPythonExport:\n",
    "    systemExample=\"caspase-1\"\n",
    "    if systemExample == \"UbqCHARMM\":\n",
    "        %cd /home/zharmad/host/projects/Ubq-md\n",
    "    elif systemExample == \"UbqAthi\":\n",
    "        %cd /home/zharmad/host/shared-colleague/Ubq-2017\n",
    "    elif systemExample == \"periplasmic\":\n",
    "        %cd /home/zharmad/projects/periplasmic/leucine-binding_protein\n",
    "    elif systemExample == \"caspase-1\":\n",
    "        %cd /home/zharmad/host/projects/caspase-1        \n",
    "    elif systemExample == \"CFTR\":\n",
    "        %cd /home/zharmad/projects/cftr/DyNetAn\n",
    "    else:\n",
    "        %cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# = = = Customised workflow control parameters for publication examples.\n",
    "if not bPythonExport:\n",
    "    numCoresAvailable = 6\n",
    "    if systemExample == \"UbqCHARMM\":\n",
    "        # apo1 apo2 apo3\n",
    "        state=\"apo1\" ; workDir = \"./apo-md01\"\n",
    "        topFile = \"./tops/prot-segids.pdb\"\n",
    "        trjFiles= os.path.join(workDir, \"prot-masses.xtc\" )\n",
    "        numWinds = 5 ; numSampledFrames = 1000\n",
    "        pathToData = \"./dynetan\"\n",
    "        fileNameRoot = \"%s_%ix%i\" % (state, numWinds, numSampledFrames)\n",
    "        fullPathRoot = os.path.join(pathToData, fileNameRoot)\n",
    "        #segIDs = [\"UBQ\"] ; h2oName = [\"SOL\"]\n",
    "    elif systemExample == \"UbqAthi\":\n",
    "        # UbqI13V  UbqI23A  UbqI30A  UbqL43A  UbqL67A  UbqL69A  UbqV17A  UbqWT\n",
    "        state=\"UbqV17A\" ; workDir = \"./%s\" % state\n",
    "        topFile = os.path.join(workDir, \"reference.pdb\" )\n",
    "        trjFiles= os.path.join(workDir, \"traj-1ns.xtc\" )\n",
    "        numWinds = 5 ; numSampledFrames = 200\n",
    "        pathToData = \"./dynetan\"\n",
    "        fileNameRoot = \"%s_%ix%i\" % (state, numWinds, numSampledFrames)\n",
    "        fullPathRoot = os.path.join(pathToData, fileNameRoot)\n",
    "        #segIDs = [\"UBQ\"] ; h2oName = [\"SOL\"]        \n",
    "    elif systemExample == \"periplasmic\":\n",
    "        # apo holo-leu\n",
    "        state=\"apo\" ; workDir = \"./apo\"\n",
    "        topFile = \"./apo/tops/prot-segids.pdb\"\n",
    "        trjFiles= os.path.join(workDir, \"protcent.xtc\" )\n",
    "        numWinds = 5 ; numSampledFrames = 200\n",
    "        pathToData = \"./dynetan\"\n",
    "        fileNameRoot = \"%s_%ix%i\" % (state, numWinds, numSampledFrames)\n",
    "        fullPathRoot = os.path.join(pathToData, fileNameRoot)\n",
    "        #segIDs = [\"LBP\"] ; h2oName = [\"SOL\"]\n",
    "        if state != \"apo\":\n",
    "            bHasInterfaceDefinitions = True\n",
    "            seltextInterfaceA=\"resid 15 18 77 78 79 80 100 101 102 103 118 121 124 150 202 226 227 276\"\n",
    "            seltextInterfaceB=\"resid 347\"\n",
    "    elif systemExample == \"caspase-1\":\n",
    "        # off-state on-state\n",
    "        state=\"off-state\" ; workDir = \"./off-state\"\n",
    "        topFile = \"%s/apo-em.pdb\" % workDir\n",
    "        trjFiles= os.path.join(workDir, \"prod/centered.xtc\" )\n",
    "        numWinds = 2 ; numSampledFrames = 5\n",
    "        pathToData = \"./dynetan\"\n",
    "        fileNameRoot = \"%s_%ix%i\" % (state, numWinds, numSampledFrames)\n",
    "        fullPathRoot = os.path.join(pathToData, fileNameRoot)\n",
    "        #segIDs = [\"C1A\",\"C1B\",\"C2A\",\"C2B\"] ; h2oName = [\"SOL\"]\n",
    "        bIncludeSolvent=True\n",
    "    elif systemExample == \"CFTR\":\n",
    "        # Define mutant file IO locations. wt, P67L, E56K, R75Q, dF508 , S945L\n",
    "        allele=\"wt\" ; temperature=\"310K\" ; nRepl=6\n",
    "        workDir = \"./trajectories/%s/%s/\" % (allele, temperature)\n",
    "        topFile = os.path.join(workDir, \"1/clustered_d3.5_r0.50.pdb\")\n",
    "        trjFiles=[]\n",
    "        for i in range(1,nRepl+1):\n",
    "            trjFiles.append(os.path.join(workDir, \"%i/clustered_d3.5_r0.50.xtc\" %i))\n",
    "        pathToData = \"./results/%s/%s/\" % (allele, temperature)\n",
    "        fileNameRoot = \"1to%i\" % nRepl\n",
    "        fullPathRoot = os.path.join(pathToData, fileNameRoot)        \n",
    "        numWinds = 5 ; numSampledFrames = 200\n",
    "        #segIDs = [\"LAS\",\"TD1\",\"ND1\",\"RDO\",\"TD2\",\"ND2\",\"CTR\",\"LIP\",\"ATP\",\"POT\",\"CLA\"]\n",
    "        segIDs = [\"LAS\",\"TD1\",\"ND1\",\"RDO\",\"TD2\",\"ND2\",\"CTR\",\"CRY\"]\n",
    "        h2oName = [\"SOL\"]\n",
    "        bIncludeSolvent=True\n",
    "    else:\n",
    "        raise KeyboardInterrupt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if numCoresAvailable>1:\n",
    "    strBackend=\"openmp\"\n",
    "else:\n",
    "    strBackend=\"serial\"\n",
    "\n",
    "if not os.path.exists(pathToData):\n",
    "    os.makedirs(pathToData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-14T20:02:26.989963Z",
     "start_time": "2020-04-14T20:02:26.973220Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Number of sampled frames for automatic selection of solvent and ions.\n",
    "# numAutoFrames = numSampledFrames*numWinds\n",
    "\n",
    "# Network Analysis will make one node per protein residue (in the alpha carbon)\n",
    "# For all other residues, the user must specify atom(s) that will represent a node.\n",
    "# ...\n",
    "# We also need to know the heavy atoms that compose each node group.\n",
    "\n",
    "customResNodes = {}\n",
    "usrNodeGroups = {}\n",
    "\n",
    "# Cater to HSD and HSE in the CHARMM forcefield.\n",
    "# Lip: Uses POPC as a reference. Node designations include:\n",
    "#      ...zwitterion centers, ester centers, and two additional carbon centers for each tail capturing ~7 atoms.\n",
    "#      ...heavy atom assignment based on charge groups in CHARMMM36\n",
    "#      ...a PSFGEN error means that the naming of carbons C216 -> 6C12.\n",
    "#customResNodes[\"HSD\"] = [\"CA\"]\n",
    "#usrNodeGroups[\"HSD\"] = {}\n",
    "#usrNodeGroups[\"HSD\"][\"CA\"] = set(\"N CA CB ND1 CG CE1 NE2 CD2 C O\".split())\n",
    "#customResNodes[\"HSE\"] = [\"CA\"]\n",
    "#usrNodeGroups[\"HSE\"] = {}\n",
    "#usrNodeGroups[\"HSE\"][\"CA\"] = set(\"N CA CB ND1 CG CE1 NE2 CD2 C O\".split())\n",
    "\n",
    "customResNodes[\"K\"] = [\"K\"]\n",
    "usrNodeGroups[\"K\"] = {}\n",
    "usrNodeGroups[\"K\"][\"K\"] = set(\"K\".split())\n",
    "\n",
    "customResNodes[\"CL\"] = [\"CL\"]\n",
    "usrNodeGroups[\"CL\"] = {}\n",
    "usrNodeGroups[\"CL\"][\"CL\"] = set(\"CL\".split())\n",
    "\n",
    "customResNodes[\"SOL\"] = [\"OW\"]\n",
    "usrNodeGroups[\"SOL\"] = {}\n",
    "usrNodeGroups[\"SOL\"][\"OW\"] = set(\"OW HW1 HW2\".split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################\n",
    "### Load info to object\n",
    "\n",
    "dnap.setNumWinds(numWinds)\n",
    "dnap.setNumSampledFrames(numSampledFrames)\n",
    "dnap.setCutoffDist(cutoffDist)\n",
    "dnap.setContactPersistence(contactPersistence)\n",
    "dnap.seth2oName(h2oName)\n",
    "dnap.setSegIDs(segIDs)\n",
    "\n",
    "dnap.setCustomResNodes(customResNodes)\n",
    "dnap.setUsrNodeGroups(usrNodeGroups)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the trajectory\n",
    "\n",
    "Our Generalized Network Analysis leverages the MDAnalysis package to create a *universe* that contains all the trajectory and system information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-14T20:02:28.159684Z",
     "start_time": "2020-04-14T20:02:26.993405Z"
    }
   },
   "outputs": [],
   "source": [
    "dnap.loadSystem(topFile,trjFiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# = = = First check if requests are sane.\n",
    "if numWinds*numSampledFrames > dnap.workU.trajectory.n_frames:\n",
    "    print(\"= = ERROR: You have requested more simulation frames to be analysed than are available!\")\n",
    "    if bPythonExport:\n",
    "        import sys\n",
    "        sys.exit()\n",
    "    else:\n",
    "        raise KeyboardInterrupt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# = = = Attempt to predict segment IDs to be analysed, if not given.\n",
    "ionSegIDs   = ['ION','SOD','CLA','POT','HET','NA','K','CL']\n",
    "waterSegIDs = ['HOH','SOL','WAT','TIP','H2O']\n",
    "if segIDs == []:\n",
    "    # = = = grab every segment that is not named after likely simple ion or water segments.\n",
    "    soluteIDs = []\n",
    "    for s in dnap.workU.segments.segids:\n",
    "        if (not s in ionSegIDs) and (not s in waterSegIDs):\n",
    "            soluteIDs.append( s )\n",
    "    dnap.setSegIDs( soluteIDs )\n",
    "    print(\"= = Automated solute segemnt prodiction has assigned %s to be included for analysis.\" & soluteIDs)\n",
    "if h2oName == []:\n",
    "    # = = = Search the segments for a name that sounds like water\n",
    "    for s in waterSegIDs:\n",
    "        if s in dnap.workU.segments.segids:\n",
    "            h2oName = s\n",
    "            break\n",
    "    if h2oName != []:\n",
    "        dnap.seth2oName(h2oName)\n",
    "    else:\n",
    "        # = = = Is possibly a protein-only trajectory. Give a dummy argument.\n",
    "        dnap.seth2oName(['HOH'])\n",
    "    print(\"= = Automated water segemnt prodiction has assigned %s to be the water segment ID.\" & h2oName)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checks segments and residue names\n",
    "\n",
    "This is important to know if there are residues in the structure that we didn't know of, and need to be addresssed so that network analysis can create nodes in all selected residues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-14T20:02:28.485023Z",
     "start_time": "2020-04-14T20:02:28.187188Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mResidue verification:\n",
      "\u001b[39m\n",
      "---> SegID  \u001b[32mC1A \u001b[39m: 20 unique residue types:\n",
      "{'ARG', 'ALA', 'SER', 'TYR', 'MET', 'CYS', 'GLY', 'GLN', 'GLU', 'TRP', 'LEU', 'LYS', 'PRO', 'HIS', 'THR', 'VAL', 'ASP', 'ASN', 'ILE', 'PHE'}\n",
      "\n",
      "---> SegID  \u001b[32mC1B \u001b[39m: 20 unique residue types:\n",
      "{'ARG', 'ALA', 'SER', 'TYR', 'MET', 'CYS', 'GLY', 'GLN', 'GLU', 'TRP', 'LEU', 'LYS', 'PRO', 'HIS', 'THR', 'VAL', 'ASP', 'ASN', 'ILE', 'PHE'}\n",
      "\n",
      "---> SegID  \u001b[32mC2A \u001b[39m: 20 unique residue types:\n",
      "{'ARG', 'ALA', 'SER', 'TYR', 'MET', 'CYS', 'GLY', 'GLN', 'GLU', 'TRP', 'LEU', 'LYS', 'PRO', 'HIS', 'THR', 'VAL', 'ASP', 'ASN', 'ILE', 'PHE'}\n",
      "\n",
      "---> SegID  \u001b[32mC2B \u001b[39m: 20 unique residue types:\n",
      "{'ARG', 'ALA', 'SER', 'TYR', 'MET', 'CYS', 'GLY', 'GLN', 'GLU', 'TRP', 'LEU', 'LYS', 'PRO', 'HIS', 'THR', 'VAL', 'ASP', 'ASN', 'ILE', 'PHE'}\n",
      "\n",
      "---> 20 total selected residue types:\n",
      "{'ARG', 'ALA', 'SER', 'TYR', 'MET', 'CYS', 'GLY', 'GLN', 'GLU', 'TRP', 'LEU', 'LYS', 'PRO', 'HIS', 'THR', 'VAL', 'ASP', 'ASN', 'ILE', 'PHE'}\n",
      "\n",
      "---> 3 \u001b[31mnot-selected\u001b[39m residue types in other segments:\n",
      "{'CL', 'SOL', 'NA'}\n",
      "\n",
      "---> 23 total residue types:\n",
      "{'ARG', 'NA', 'ALA', 'SER', 'TYR', 'MET', 'CYS', 'GLY', 'GLN', 'GLU', 'TRP', 'SOL', 'LEU', 'CL', 'LYS', 'PRO', 'HIS', 'THR', 'VAL', 'ASP', 'ASN', 'ILE', 'PHE'}\n",
      "\n",
      "---> \u001b[32m508 total residues\u001b[39m were selected for network analysis.\n",
      "\n",
      "\u001b[34mSegments verification:\n",
      "\u001b[39m\n",
      "---> 4 \u001b[32mselected\u001b[39m segments:\n",
      "['C1A', 'C1B', 'C2A', 'C2B']\n",
      "\n",
      "---> 2 \u001b[31mnot-selected\u001b[39m segments:\n",
      "['ION', 'SOL']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dnap.checkSystem()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Automatically identify crystallographic waters and ions.\n",
    "\n",
    "In this section we identify all residues which will be checked for connectivity with selected segments.\n",
    "\n",
    "- First, we define if all solvent molecules will be checked, or if just ions, ligands, lipids, and other molecules will be checked.\n",
    "\n",
    "- Second, we sample a small set of frames from the trajectory to select likely residues, then we check all trajectory to see if they are closer than the cutoff distance for at least x% of the simulation (where x is the \"contact persistence\" fraction of the trajectory).\n",
    "\n",
    "- Third, we load the trajectory of the relevant atoms to memory to speed up the analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-14T20:02:35.528972Z",
     "start_time": "2020-04-14T20:02:28.494862Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking 10 frames (striding 1000)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f021887827440ccaa0287def9b1ca12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), IntProgress(value=1, max=1), Label(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17 extra residues will be added to the system.\n",
      "The initial universe had 71749 atoms.\n",
      "The final universe has 4071 atoms.\n",
      "Loading universe to memory...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zharmad/miniconda3/lib/python3.8/site-packages/MDAnalysis/analysis/base.py:280: DeprecationWarning: The structure of the `results` array will change in MDAnalysis version 2.0.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "dnap.selectSystem(withSolvent=bIncludeSolvent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare network representation of the system\n",
    "\n",
    "Here we check that we know how to treat all types of residues in the final selection. Every residue will generate one or more nodes in the final network. Then we store the groups of atoms that define each node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dnap.getU().residues[300]\n",
    "# dnap.getU().residues[300].resname\n",
    "# 'C13' in set.union(*dnap.resNodeGroups['POPC'].values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-14T20:02:36.062392Z",
     "start_time": "2020-04-14T20:02:35.535533Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing nodes...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cb4b825d5ef4415ac9dd5d9dea3b6d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), IntProgress(value=1, max=1), Label(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nodes are ready for network analysis.\n"
     ]
    }
   ],
   "source": [
    "dnap.prepareNetwork()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Align the trajectory based on selected segments\n",
    "\n",
    "We align the trajectory to its first frame using heavy atoms (non-hydrogen) from the selected segments. In the process, we also transfer the trajectory to the computer memory, so that future analysis and manipulations are completed faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-14T20:02:37.698151Z",
     "start_time": "2020-04-14T20:02:36.082241Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b399e7738aca44d8a4d771863d016724",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10001 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# If your system is too large, you can turn off the \"in memory\" option, at a cost for performance.\n",
    "dnap.alignTraj(inMemory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select residues that are closer than 4.5A for more than 75% of simulation\n",
    "\n",
    "Creates an N-by-N matrix for all N nodes in the selected region, and automatically selected nodes (ions, solvent).\n",
    "\n",
    "The following cell defines efficient functions to run the analysis and create a contact matrix. We leverage both MDAnalysis parallel contact detection tools, as well as accelerated Numba and Cython function. After creating the contact matrix, we remove any automatically selected nodes that have insuficient persistance, and filter the contacts by (optionally) removing contacts between nodes in consecutive residues in a protein or nucleic chain.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Attention** For every time you start this Jupyter Notebook, the first time you execute this function may take significanlty longer (several seconds) to start. This is because we use *Cython* and *Numba* to compile functions \"on-demand\", and a new compilation may be necessary after the notebook is re-started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-14T20:03:25.577099Z",
     "start_time": "2020-04-14T20:02:37.700995Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de62989b45af4bd3974e7ffe1904127a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), IntProgress(value=1, max=1), Label(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We found 1 nodes with no contacts.\n",
      "We found 2387 contacting pairs out of 137550 total pairs of nodes.\n",
      "(That's 1.7%, by the way)\n"
     ]
    }
   ],
   "source": [
    "# To speed-up the contact matrix calculation, a larger stride can be selected, at a cost for precision.\n",
    "dnap.findContacts(stride=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing contacts between nodes in the same residue.\n",
    "\n",
    "The following function guarantees that there will be no \"self-contacts\" (contacts between a node and itself), and gives you the opportunity to remove contacts between nodes in consecutive residues (such as sequential amino acids in the same chain, removing back-bone interactions). \n",
    "\n",
    "The function also removes nodes that are never in contact with any other node in the system (such as the ends of flexible chains, or residues in flexible loops). This will automatically update the MDanalysis universe and related network informatio, such as number of nodes and atom-to-node mappings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-14T20:03:30.345737Z",
     "start_time": "2020-04-14T20:03:25.588031Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcb352989dfa427abce9ff73a36fc064",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), IntProgress(value=1, max=1), Label(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc5df6c0d17e4ba2a24ad87095153ffd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), IntProgress(value=1, max=1), Label(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Window: 0\n",
      "We found 2265 contacting pairs out of 137550 total pairs of nodes.\n",
      "(That's 1.647%, by the way)\n",
      "Window: 1\n",
      "We found 2294 contacting pairs out of 137550 total pairs of nodes.\n",
      "(That's 1.668%, by the way)\n",
      "\n",
      "Removing isolated nodes...\n",
      "\n",
      "We found 1 nodes with no contacts.\n",
      "\n",
      "Isolated nodes removed. We now have 524 nodes in the system\n",
      "\n",
      "Running new contact matrix sanity check...\n",
      "We found 0 nodes with no contacts.\n",
      "We found 2387 contacting pairs out of 137026 total pairs of nodes.\n",
      "(That's 1.7%, by the way)\n",
      "\n",
      "Updating Universe to reflect new node selection...\n",
      "Updating atom-to-node mapping...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5b99a4a4f1c468287b0ba80292d53e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), IntProgress(value=1, max=1), Label(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dnap.filterContacts(notSameRes=True, notConsecutiveRes=False, removeIsolatedNodes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Generalized Correlation with Python/Numba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-14T20:03:43.328370Z",
     "start_time": "2020-04-14T20:03:30.348061Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating correlations...\n",
      "\n",
      "Using window length of 5000 simulation steps.\n",
      "- > Using multi-core implementation with 6 threads.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5840f00f5b74b349f4b357abbd4bc70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), IntProgress(value=1, max=1), Label(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "410452058f7f4c69b00a678d5c62af32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), IntProgress(value=1, max=1), Label(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# We can calculate generalized correlaions in parallel using Python's multiprocessing package.\n",
    "dnap.calcCor(ncores=numCoresAvailable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate cartesian distances between all nodes in the selected system.\n",
    "\n",
    "Here, we will calculate the **shortest** distance between atoms in all pairs of nodes. It is similar to the contact matrix calculation, but we check all distances and keep the shortest one to use in our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4070,)\n"
     ]
    }
   ],
   "source": [
    "print( dnap.atomToNode.shape )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-14T20:03:54.619509Z",
     "start_time": "2020-04-14T20:03:43.331634Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling a total of 10 frames from 2 windows (5 per window)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c9fee05f68a4176b1218ce8794a9af1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), IntProgress(value=1, max=1), Label(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e6bd668e1ca463d934479efd43abacc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), IntProgress(value=1, max=1), Label(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# We can leverage MDanalysis parallelization options with backend=\"serial\" or backend=\"openmp\".\n",
    "# For very small systems, the serial can be faster!\n",
    "dnap.calcCartesian(backend=strBackend)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network Calculations\n",
    "Create a graph from our correlation matrix. Different properties are calculated:\n",
    "\n",
    "*Density* measures how connected the graph is compared to how connected it *could* be. It is the ratio between edges in the graph over all possible edges between all pairs of nodes.\n",
    "\n",
    "*Transitivity* maesures the triadic closure, comparing present triangles to possible triangles. In a triangle, if A is connected to B, and B connected to C, then A is connected to C.\n",
    "\n",
    "*Degree* measures the number of connections a node has.\n",
    "\n",
    "(Reference)[1]\n",
    "\n",
    "[1]:https://programminghistorian.org/en/lessons/exploring-and-analyzing-network-data-with-python#advanced-networkx-community-detection-with-modularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-14T20:03:56.272811Z",
     "start_time": "2020-04-14T20:03:54.622084Z"
    }
   },
   "outputs": [],
   "source": [
    "dnap.calcGraphInfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-14T20:03:56.283952Z",
     "start_time": "2020-04-14T20:03:56.276920Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: \n",
      "Type: Graph\n",
      "Number of nodes: 524\n",
      "Number of edges: 2265\n",
      "Average degree:   8.6450\n"
     ]
    }
   ],
   "source": [
    "# Basic information of the network as interpreted as a graph.\n",
    "print( nx.info(dnap.nxGraphs[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-14T20:03:56.507667Z",
     "start_time": "2020-04-14T20:03:56.287113Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Window 0 -----\n",
      "Density: 0.0165\n",
      "Transitivity: 0.4159\n",
      "\n",
      "----- Window 1 -----\n",
      "Density: 0.0167\n",
      "Transitivity: 0.4139\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Both density and transitivity are scaled from 0 to 1\n",
    "for win in range(dnap.numWinds):\n",
    "    print(\"----- Window {} -----\".format(win))\n",
    "    print(\"Density:\", round( nx.density(dnap.nxGraphs[win]), 4) )\n",
    "    print(\"Transitivity:\", round( nx.transitivity(dnap.nxGraphs[win]), 4) )\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-14T20:03:56.530227Z",
     "start_time": "2020-04-14T20:03:56.511898Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Window 0 -----\n",
      "Top 10 nodes by degree: [node --> degree : selection]\n",
      " 223 --> 18 : resname ARG and resid 374 and segid C1B\n",
      " 477 --> 16 : resname ARG and resid 374 and segid C2B\n",
      "  79 --> 15 : resname MET and resid 211 and segid C1A\n",
      " 179 --> 15 : resname PHE and resid 330 and segid C1B\n",
      " 220 --> 15 : resname ARG and resid 371 and segid C1B\n",
      "\n",
      "----- Window 1 -----\n",
      "Top 10 nodes by degree: [node --> degree : selection]\n",
      " 223 --> 18 : resname ARG and resid 374 and segid C1B\n",
      " 477 --> 17 : resname ARG and resid 374 and segid C2B\n",
      " 219 --> 15 : resname PHE and resid 370 and segid C1B\n",
      " 220 --> 15 : resname ARG and resid 371 and segid C1B\n",
      " 333 --> 15 : resname MET and resid 211 and segid C2A\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "# We can check the nodes that have the most connections in each window.\n",
    "for win in range(dnap.numWinds):\n",
    "    print(\"----- Window {} -----\".format(win))\n",
    "    \n",
    "    sorted_degree = sorted(dnap.getDegreeDict(win).items(), key=itemgetter(1), reverse=True)\n",
    "    \n",
    "    print(\"Top 10 nodes by degree: [node --> degree : selection]\")\n",
    "    for n,d in sorted_degree[:5]:\n",
    "        print(\"{0:>4} --> {1:>2} : {2}\".format(n, d, getSelFromNode(n, dnap.nodesAtmSel)))\n",
    "    \n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate optimal paths\n",
    "We choose the Floyd Warshall algorithm[1]. This uses the **correlations as weights** to calculate network distances and shortest distances.\n",
    "\n",
    "[1]:https://networkx.github.io/documentation/stable/reference/algorithms/generated/networkx.algorithms.shortest_paths.dense.floyd_warshall.html?highlight=warshall#networkx.algorithms.shortest_paths.dense.floyd_warshall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-14T20:04:03.692662Z",
     "start_time": "2020-04-14T20:03:56.533388Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3979b895d6b43f193dd283ec196c4d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), IntProgress(value=1, max=1), Label(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dnap.calcOptPaths(ncores=numCoresAvailable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate betweenness\n",
    "\n",
    "We calculate both betweenness centrality[1] for edges and eigenvector centrality[2] for nodes.\n",
    "\n",
    "[1]:https://networkx.github.io/documentation/stable/reference/algorithms/generated/networkx.algorithms.centrality.edge_betweenness_centrality.html?highlight=betweenness#networkx.algorithms.centrality.edge_betweenness_centrality\n",
    "[2]:https://networkx.github.io/documentation/networkx-1.10/reference/generated/networkx.algorithms.centrality.eigenvector_centrality.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-14T20:04:04.371111Z",
     "start_time": "2020-04-14T20:04:03.698752Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f68d689445c8409d9a28b61e8584421e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), IntProgress(value=1, max=1), Label(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dnap.calcBetween(ncores=numCoresAvailable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-14T20:04:04.383621Z",
     "start_time": "2020-04-14T20:04:04.374440Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nodes (127, 362) have betweenes 0.043 and correlation 0.451.\n",
      "Nodes (362, 364) have betweenes 0.033 and correlation 0.889.\n",
      "Nodes (219, 220) have betweenes 0.028 and correlation 0.923.\n",
      "Nodes (149, 219) have betweenes 0.028 and correlation 0.399.\n",
      "Nodes (220, 500) have betweenes 0.026 and correlation 0.315.\n"
     ]
    }
   ],
   "source": [
    "from itertools import islice\n",
    "\n",
    "# Pairs of nodes with highest Betweeness values, compared to their correlation values (in Window 0)\n",
    "for k,v in islice(dnap.btws[0].items(),5):\n",
    "    print(\"Nodes {} have betweenes {} and correlation {}.\".format(k, \n",
    "                                                                  round(v,3), \n",
    "                                                                  round(dnap.corrMatAll[0, k[0], k[1]], 3) ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Turn to node centrality instead of edge centrality:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-14T20:04:04.706385Z",
     "start_time": "2020-04-14T20:04:04.386209Z"
    }
   },
   "outputs": [],
   "source": [
    "dnap.calcEigenCentral()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate communities\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using **Louvain heuristices** is feasible. \n",
    "This method also maximizes the modularity of the network.\n",
    "\n",
    "http://iopscience.iop.org/article/10.1088/1742-5468/2008/10/P10008/meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-14T20:04:04.985294Z",
     "start_time": "2020-04-14T20:04:04.712272Z"
    }
   },
   "outputs": [],
   "source": [
    "dnap.calcCommunities()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-14T20:04:04.997552Z",
     "start_time": "2020-04-14T20:04:04.988395Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modularity Class  2:  71 nodes.\n",
      "Modularity Class 11:  51 nodes.\n",
      "Modularity Class  4:  47 nodes.\n",
      "Modularity Class  8:  47 nodes.\n",
      "Modularity Class  1:  44 nodes.\n",
      "Modularity Class  6:  42 nodes.\n",
      "Modularity Class  9:  41 nodes.\n",
      "Modularity Class 13:  40 nodes.\n",
      "Modularity Class  0:  35 nodes.\n",
      "Modularity Class  7:  24 nodes.\n",
      "Modularity Class 12:  22 nodes.\n",
      "Modularity Class  5:  21 nodes.\n",
      "Modularity Class 10:  21 nodes.\n",
      "Modularity Class  3:  18 nodes.\n"
     ]
    }
   ],
   "source": [
    "# Sort communities based on number of nodes\n",
    "for comIndx in dnap.nodesComm[0][\"commOrderSize\"]:\n",
    "    print(\"Modularity Class {0:>2}: {1:>3} nodes.\".format(comIndx, len(dnap.nodesComm[0][\"commNodes\"][comIndx])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-14T20:04:05.099322Z",
     "start_time": "2020-04-14T20:04:05.000447Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modularity Class 2 (71 nodes) Sorted by Eigenvector Centrality:\n",
      "Name:   79 | Degree: 14 | Eigenvector Centrality: 0.08072045586896259\n",
      "Name:   74 | Degree: 12 | Eigenvector Centrality: 0.07309015923508207\n",
      "Name:   38 | Degree: 14 | Eigenvector Centrality: 0.06356710683400515\n",
      "Name:   82 | Degree: 10 | Eigenvector Centrality: 0.06902842190785805\n",
      "Name:   76 | Degree: 10 | Eigenvector Centrality: 0.05655282279950122\n",
      "\n",
      "Modularity Class 3 (18 nodes) Sorted by Eigenvector Centrality:\n",
      "Name:   54 | Degree: 13 | Eigenvector Centrality: 0.06889422385735083\n",
      "Name:   50 | Degree:  8 | Eigenvector Centrality: 0.04125924843110719\n",
      "Name:   53 | Degree: 12 | Eigenvector Centrality: 0.0562058260561231\n",
      "Name:   57 | Degree: 13 | Eigenvector Centrality: 0.06636348473837075\n",
      "Name:   61 | Degree: 12 | Eigenvector Centrality: 0.05691158708423974\n",
      "\n",
      "Modularity Class 1 (44 nodes) Sorted by Eigenvector Centrality:\n",
      "Name:  129 | Degree: 12 | Eigenvector Centrality: 0.04691658821770893\n",
      "Name:  132 | Degree: 12 | Eigenvector Centrality: 0.03960400782970028\n",
      "Name:  128 | Degree:  8 | Eigenvector Centrality: 0.030120221853081015\n",
      "Name:  126 | Degree:  7 | Eigenvector Centrality: 0.02267179796556999\n",
      "Name:  125 | Degree:  8 | Eigenvector Centrality: 0.02336053216788782\n",
      "\n",
      "Modularity Class 5 (21 nodes) Sorted by Eigenvector Centrality:\n",
      "Name:  153 | Degree:  9 | Eigenvector Centrality: 0.011887549657196232\n",
      "Name:  195 | Degree:  8 | Eigenvector Centrality: 0.01778765222857589\n",
      "Name:  154 | Degree:  9 | Eigenvector Centrality: 0.005938260911691309\n",
      "Name:  182 | Degree:  7 | Eigenvector Centrality: 0.006644362103103471\n",
      "Name:  183 | Degree:  9 | Eigenvector Centrality: 0.01253453438953288\n",
      "\n",
      "Modularity Class 8 (47 nodes) Sorted by Eigenvector Centrality:\n",
      "Name:  203 | Degree: 11 | Eigenvector Centrality: 0.09907116508586127\n",
      "Name:  199 | Degree:  9 | Eigenvector Centrality: 0.07059643077146437\n",
      "Name:  202 | Degree: 13 | Eigenvector Centrality: 0.1243880879844076\n",
      "Name:  205 | Degree: 13 | Eigenvector Centrality: 0.1683019882569102\n",
      "Name:  201 | Degree: 11 | Eigenvector Centrality: 0.11972727984622004\n",
      "\n",
      "Modularity Class 7 (24 nodes) Sorted by Eigenvector Centrality:\n",
      "Name:  176 | Degree: 13 | Eigenvector Centrality: 0.01669038226898199\n",
      "Name:  177 | Degree: 13 | Eigenvector Centrality: 0.023218971034319216\n",
      "Name:  240 | Degree: 11 | Eigenvector Centrality: 0.025790084213687645\n",
      "Name:  175 | Degree: 12 | Eigenvector Centrality: 0.0128582143266456\n",
      "Name:  241 | Degree: 12 | Eigenvector Centrality: 0.05173444558894841\n",
      "\n",
      "Modularity Class 0 (35 nodes) Sorted by Eigenvector Centrality:\n",
      "Name:  247 | Degree: 11 | Eigenvector Centrality: 0.04679723867288543\n",
      "Name:  249 | Degree: 11 | Eigenvector Centrality: 0.05510402703730552\n",
      "Name:  248 | Degree: 11 | Eigenvector Centrality: 0.05083571853628997\n",
      "Name:  251 | Degree: 10 | Eigenvector Centrality: 0.03293070254515082\n",
      "Name:  250 | Degree: 12 | Eigenvector Centrality: 0.03975441123073099\n",
      "\n",
      "Modularity Class 11 (51 nodes) Sorted by Eigenvector Centrality:\n",
      "Name:  477 | Degree: 17 | Eigenvector Centrality: 0.12114275597558534\n",
      "Name:  473 | Degree: 14 | Eigenvector Centrality: 0.11759780178473402\n",
      "Name:  470 | Degree: 14 | Eigenvector Centrality: 0.10331157368250285\n",
      "Name:  476 | Degree: 14 | Eigenvector Centrality: 0.14379869898619627\n",
      "Name:  495 | Degree: 13 | Eigenvector Centrality: 0.07028927941196313\n",
      "\n",
      "Modularity Class 6 (42 nodes) Sorted by Eigenvector Centrality:\n",
      "Name:  430 | Degree: 12 | Eigenvector Centrality: 0.03711629123411864\n",
      "Name:  429 | Degree: 12 | Eigenvector Centrality: 0.032050125791643055\n",
      "Name:  428 | Degree: 12 | Eigenvector Centrality: 0.03245473973674809\n",
      "Name:  425 | Degree: 14 | Eigenvector Centrality: 0.030573446890143074\n",
      "Name:  384 | Degree: 11 | Eigenvector Centrality: 0.023412545444799725\n",
      "\n",
      "Modularity Class 4 (47 nodes) Sorted by Eigenvector Centrality:\n",
      "Name:  362 | Degree:  6 | Eigenvector Centrality: 0.005511668087106815\n",
      "Name:  337 | Degree: 11 | Eigenvector Centrality: 0.02124808174861777\n",
      "Name:  365 | Degree: 12 | Eigenvector Centrality: 0.0215874045032606\n",
      "Name:  333 | Degree: 15 | Eigenvector Centrality: 0.019454938407675437\n",
      "Name:  364 | Degree:  9 | Eigenvector Centrality: 0.010844872811952375\n",
      "\n",
      "Modularity Class 9 (41 nodes) Sorted by Eigenvector Centrality:\n",
      "Name:  467 | Degree: 10 | Eigenvector Centrality: 0.0700840344806732\n",
      "Name:  463 | Degree: 11 | Eigenvector Centrality: 0.0748068607614163\n",
      "Name:  273 | Degree:  8 | Eigenvector Centrality: 0.02129598990011665\n",
      "Name:  464 | Degree: 12 | Eigenvector Centrality: 0.07137910878435362\n",
      "Name:  499 | Degree: 12 | Eigenvector Centrality: 0.03410927826341031\n",
      "\n",
      "Modularity Class 13 (40 nodes) Sorted by Eigenvector Centrality:\n",
      "Name:  403 | Degree: 12 | Eigenvector Centrality: 0.04685492715927416\n",
      "Name:  402 | Degree: 10 | Eigenvector Centrality: 0.03237942677377355\n",
      "Name:  404 | Degree: 11 | Eigenvector Centrality: 0.03505158761850723\n",
      "Name:  401 | Degree: 10 | Eigenvector Centrality: 0.0327076749344919\n",
      "Name:  405 | Degree:  9 | Eigenvector Centrality: 0.025263746192200256\n",
      "\n",
      "Modularity Class 12 (22 nodes) Sorted by Eigenvector Centrality:\n",
      "Name:  435 | Degree:  8 | Eigenvector Centrality: 0.028236247536496253\n",
      "Name:  406 | Degree:  9 | Eigenvector Centrality: 0.013927042802674186\n",
      "Name:  407 | Degree: 10 | Eigenvector Centrality: 0.009721374476110425\n",
      "Name:  408 | Degree: 10 | Eigenvector Centrality: 0.006233095273767304\n",
      "Name:  437 | Degree:  7 | Eigenvector Centrality: 0.008951909512168475\n",
      "\n",
      "Modularity Class 10 (21 nodes) Sorted by Eigenvector Centrality:\n",
      "Name:  352 | Degree: 12 | Eigenvector Centrality: 0.014267554888040422\n",
      "Name:  346 | Degree: 13 | Eigenvector Centrality: 0.009244151810271318\n",
      "Name:  277 | Degree:  5 | Eigenvector Centrality: 0.004294716747394405\n",
      "Name:  351 | Degree:  9 | Eigenvector Centrality: 0.007680378119271237\n",
      "Name:  276 | Degree:  4 | Eigenvector Centrality: 0.004503564885414916\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Sort communities based on the node with highest eigenvector centrality\n",
    "for comIndx in dnap.nodesComm[0][\"commOrderEigenCentr\"]:\n",
    "    print(\"Modularity Class {0} ({1} nodes) Sorted by Eigenvector Centrality:\".format(\n",
    "                                                                    comIndx, \n",
    "                                                                len(dnap.nodesComm[0][\"commNodes\"][comIndx])))\n",
    "    for node in dnap.nodesComm[0][\"commNodes\"][comIndx][:5]:\n",
    "        print(\"Name: {0:>4} | Degree: {1:>2} | Eigenvector Centrality: {2}\".format(\n",
    "            node, dnap.nxGraphs[win].nodes[node]['degree'], dnap.nxGraphs[win].nodes[node]['eigenvector']))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process Interface Residues\n",
    "\n",
    "We now find all nodes that are close to both selections chosen by the user. That may include amino acids in the interface, as well as ligands, waters and ions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-14T20:04:06.765269Z",
     "start_time": "2020-04-14T20:04:05.102432Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd1884ca584845368f15ae650642dd3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), IntProgress(value=1, max=1), Label(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35 pairs of nodes connecting the two selections.\n",
      "34 unique nodes in interface node pairs.\n"
     ]
    }
   ],
   "source": [
    "if bHasInterfaceDefinitions:\n",
    "    dnap.interfaceAnalysis(selAstr=seltextInterfaceA, selBstr=seltextInterfaceB)\n",
    "else:\n",
    "    # Conduct analysis on dummy inputs since this is hard-coded.\n",
    "    dnap.interfaceAnalysis(selAstr=getSelFromNode(0,dnap.nodesAtmSel), selBstr=getSelFromNode(1,dnap.nodesAtmSel) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute additional graph properties here to save some time for the analysis in Step 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: btws is the same as the results derived from nx.edge_betweenness_centrality()\n",
    "for w in range(numWinds):\n",
    "    G = dnap.nxGraphs[w]\n",
    "\n",
    "    # Transfer edge-betweenness to graph.\n",
    "    for u,v in dnap.btws[w]:\n",
    "        G.edges[u,v]['btws']=dnap.btws[w][u,v]\n",
    "    # Note: edge-betweeness weighted clustering coefficient. \n",
    "    c = nx.clustering(G, weight='btws')\n",
    "    for x in range(dnap.numNodes):\n",
    "        G.nodes[x]['bwcc']=c[x]\n",
    "    # Node betweenness centrality as an alternative to eigenvector centrality.\n",
    "    c = nx.betweenness_centrality(dnap.nxGraphs[w])\n",
    "    for x in range(dnap.numNodes):\n",
    "        dnap.nxGraphs[w].nodes[x]['btws']=c[x]\n",
    "\n",
    "    # Set the name of the node for future display. Append atom names to residues that have multiple nodes.\n",
    "    # It's sometimes important to do things here in Step 1 when issues of duplicate nodes might arise.\n",
    "    nodeNames={} ; nodeSegIDs={} ; nodeAtomNames={}\n",
    "    for x in G.nodes():\n",
    "        #i=dnap.nodesAtmSel[x].index\n",
    "        nodeNames[x]  = name_node(dnap, x)\n",
    "        nodeSegIDs[x] = dnap.nodesAtmSel[x].segid\n",
    "        nodeAtomNames[x] = dnap.nodesAtmSel[x].name\n",
    "    nodeNames = clarify_duplicate_nodes( nodeNames, nodeAtomNames )\n",
    "    nx.set_node_attributes(G, nodeNames, \"name\")\n",
    "    nx.set_node_attributes(G, nodeSegIDs, \"segid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save data and reduced trajectory for visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnap.saveData(fullPathRoot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-14T20:04:07.074514Z",
     "start_time": "2020-04-14T20:04:06.955460Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We will save 4070 heavy atoms and 2 frames.\n"
     ]
    }
   ],
   "source": [
    "# This function will save a reduced DCD trajectory with the heavy atoms used for network analysis\n",
    "# A smaller trajectory can be created by choosing a \"stride\" that sub-samples the original trajectory.\n",
    "# This function will also produce a PDB file so that information on atoms and residues can be loaded to\n",
    "#    visualization software such as VMD.\n",
    "if strideDCD == 0:\n",
    "    strideDCD = dnap.workU.trajectory.n_frames-1\n",
    "print(\"We will save {} heavy atoms and {} frames.\".format(dnap.workU.atoms.n_atoms, \n",
    "                                                          len(dnap.workU.trajectory[::strideDCD]) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-14T20:04:10.709069Z",
     "start_time": "2020-04-14T20:04:07.078899Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "575d96952c874b518335b4b6985d43c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), IntProgress(value=1, max=1), Label(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zharmad/miniconda3/lib/python3.8/site-packages/MDAnalysis/coordinates/PDB.py:861: DeprecationWarning: Using the last letter of the segid for the chainID is now deprecated and will be changed in 2.0. In 2.0, the chainID attribute will be used if it exists, or a placeholder value.\n",
      "  warnings.warn(\"Using the last letter of the segid for the chainID \"\n",
      "/home/zharmad/miniconda3/lib/python3.8/site-packages/MDAnalysis/coordinates/PDB.py:722: UserWarning: Unit cell dimensions not found. CRYST1 record set to unitary values.\n",
      "  warnings.warn(\"Unit cell dimensions not found. \"\n"
     ]
    }
   ],
   "source": [
    "dnap.saveReducedTraj(fullPathRoot, stride = strideDCD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MDAnalysis may print warnings regarding missing data fields, such as altLocs, icodes, occupancies, or tempfactor, which provide information commonly found in PDB files.\n",
    "The warnings are for your information and in the context of this tutorial they are expected and do not indicate a problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis\n",
    "\n",
    "The we have finished processing the trajectory and storing all related data. We can now move on to analysis of the network properties calculated here.\n",
    "\n",
    "**All analysis code was placed in a second tutorial notebook for clarity.**\n",
    "\n",
    "\n",
    "# ---- The End ----"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
