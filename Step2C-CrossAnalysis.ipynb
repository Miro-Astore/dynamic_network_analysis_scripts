{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ab30f3-da4f-422b-90c4-a0ffe4ee9cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the python package\n",
    "import os\n",
    "from dynetan.toolkit import *\n",
    "from dynetan.viz import *\n",
    "from dynetan.proctraj import *\n",
    "from dynetan.gencor import *\n",
    "from dynetan.contact import *\n",
    "from dynetan.datastorage import *\n",
    "\n",
    "from MDAnalysis.analysis import distances as MDAdistances\n",
    "#from numpy.linalg import norm\n",
    "#from itertools import islice\n",
    "from itertools import combinations\n",
    "from scipy import stats\n",
    "from collections import OrderedDict\n",
    "\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a9356e2-c014-44ce-a2cb-574899a42e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For visualization\n",
    "from bokeh.io import output_file, output_notebook, push_notebook, show\n",
    "from bokeh import models as bokehModels\n",
    "from bokeh import transform as bokehTransform\n",
    "from bokeh import layouts as bokehLayouts\n",
    "from bokeh import plotting as bokehPlotting\n",
    "from bokeh import palettes as bokehPalettes\n",
    "from bokeh import events as bokehEvents\n",
    "# For pre-calculating CArtesian distances based on 2D embedding\n",
    "from sklearn.manifold import MDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7bb5563-78ec-4e33-a241-485c3214173c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapResidueNames={'ALA':'A','CYS':'C','ASP':'D','GLU':'E','PHE':'F',\n",
    "                 'GLY':'G','HIS':'H','HSD':'H','HSE':'H','ILE':'I','LYS':'K','LEU':'L',\n",
    "                 'MET':'M','ASN':'N','PRO':'P','GLN':'Q','ARG':'R',\n",
    "                 'SER':'S','THR':'T','VAL':'V','TRP':'W','TYR':'Y',\n",
    "                 'MG':'Mg','ATP':'Atp','POPC':'Popc','SOL':'h2o'}\n",
    "\n",
    "def name_node(dnad, node):\n",
    "    #i=dnad.nodesAtmSel[node].index\n",
    "    resname=dnad.nodesAtmSel[node].resname ; resid=dnad.nodesAtmSel[node].resid\n",
    "    return \"%s%s\" % (mapResidueNames[resname], resid)\n",
    "\n",
    "def clarify_duplicate_nodes(dictNames, dictSuffix):\n",
    "    \"\"\"\n",
    "    From two dicts with the same keys, add the respective suffix to all keys in the former that possess duplicate values.\n",
    "# For visualization\n",
    "from bokeh.io import output_file, output_notebook, push_notebook, show\n",
    "from bokeh import models as bokehModels\n",
    "from bokeh import transform as bokehTransform\n",
    "from bokeh import layouts as bokehLayouts\n",
    "from bokeh import plotting as bokehPlotting\n",
    "from bokeh import palettes as bokehPalettes\n",
    "from bokeh import events as bokehEvents\n",
    "# For pre-calculating CArtesian distances based on 2D embedding\n",
    "from sklearn.manifold import MDS    \"\"\"\n",
    "    from itertools import chain\n",
    "    dictRev = {}\n",
    "    for k, v in dictNames.items():\n",
    "        dictRev.setdefault(v, set()).add(k)\n",
    "        setDuplicateKeys = set(chain.from_iterable( v for k, v in dictRev.items() if len(v) > 1))\n",
    "    for k in setDuplicateKeys:\n",
    "        dictNames[k] = dictNames[k]+\"_\"+dictSuffix[k]\n",
    "    return dictNames  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5fbfab1-b3c0-4a6d-84c5-566a26311b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_all_graphs(workingFolder):\n",
    "    \"\"\"\n",
    "    Load all results bt\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "838f9241-6eb0-44e2-9193-aa55cad538c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simplify_graph(G, attr='segid', listIgnoredNodes=[]):\n",
    "    outG = nx.Graph()\n",
    "    for n,d in G.nodes(data=attr):\n",
    "        if d not in outG.nodes():\n",
    "            outG.add_node( d )\n",
    "            outG.nodes[d]['count']=0\n",
    "        outG.nodes[d]['count']+=1\n",
    "    for u,v,w in G.edges(data='weight'):\n",
    "        k1 = G.nodes[u][attr]\n",
    "        k2 = G.nodes[v][attr]\n",
    "        if (k1,k2) not in outG.edges():\n",
    "            outG.add_edge(k1,k2, weight=0.0)\n",
    "        outG.edges[k1,k2]['weight'] += w\n",
    "\n",
    "    # = = = Easier to remove nodes post-fact rather than going through all the if-statements.\n",
    "    for d in listIgnoredNodes:\n",
    "        if d in outG.nodes():\n",
    "            outG.remove_node( d )\n",
    "\n",
    "    return outG\n",
    "    # Hello World"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dbcf832-956f-4701-acad-7b33b56664fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "bPythonExport = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "931bb41d-d515-45f3-8ce5-790aa3f99424",
   "metadata": {},
   "source": [
    "# Initialise variables\n",
    "We will create a pandas dataframe _dfAnnotations_ to handle various catergorisation possibilities.\n",
    "This will be used to group the data from individual windows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b93d2e4-4f41-45f1-9905-cda8e403f1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not bPythonExport:\n",
    "    %cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0187d2bc-50cf-4285-9304-b2392cdd1657",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not bPythonExport:\n",
    "    # Define mutant file IO locations. wt, P67L, E56K, R75Q, S945L, dF508\n",
    "    temperature=\"310K\"\n",
    "    fileAnnotations = './list_allele_annotations.txt'\n",
    "    dfAnnotations = pd.read_csv(fileAnnotations, delimiter=' ', skipinitialspace=True, header=0)\n",
    "\n",
    "    #outputFileName = \"./results/networkView_%s_%s.html\" % (allele, temperature)\n",
    "    outputFileName = \"./networkCompare.html\"\n",
    "    \n",
    "    fileImportPos  = './CFTRGraphReferencePositions.txt'\n",
    "    fileExportPos  = './temp.txt'\n",
    "    #fileClusterDefinitions = None\n",
    "    fileClusterDefinitions = './Stable_Solvent_Clustering.cluster_definitions_d3.5_r0.50.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a7bdc8f-7eb9-4ba9-a805-944f206110eb",
   "metadata": {},
   "source": [
    "## Read graphs from DNA analysis files and extend annotation with simulation data\n",
    "The dataframe from above will be augmented below with an extra column denoting the window.\n",
    "the expected outcomes is that the index in the dataframe should strictly correspond to the index of the graph lists, so you can link all windows & graphs with their respective external annotations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d4b5ba-f244-4d89-b008-811d024ba614",
   "metadata": {},
   "outputs": [],
   "source": [
    "# = = Utilise the annotations file as a means of determining input paths.\n",
    "print(\"= = = Loading input graph data from all input paths...\")\n",
    "listG=[] ; listNWinds=[] ; listLoaded = [] ; nWarn=0\n",
    "for i in dfAnnotations.index:\n",
    "    fullPathRoot = dfAnnotations['DyNetAn_Path'][i]\n",
    "    if not os.path.exists(fullPathRoot+'.hf'):\n",
    "        print(\"= = WARNING: ...path %s does not contain DyNetAn files? Skipping.\" % fullPathRoot)\n",
    "        nWarn+=1\n",
    "        continue\n",
    "    print(\"    ...loading from path %s:\" % fullPathRoot)\n",
    "    \n",
    "    dnad = DNAdata()\n",
    "    # = = = loadFromFile will automatically output debug lines.\n",
    "    dnad.loadFromFile(fullPathRoot)\n",
    "    pdbVizFile = fullPathRoot + \"_reducedTraj.pdb\"\n",
    "    mdU = mda.Universe(pdbVizFile)\n",
    "    dnad.nodesAtmSel = mdU.atoms[ dnad.nodesIxArray ]\n",
    "    # = = = Make a simpler representation via segid, and exclude crystallographic waters as they don't comprise a cohesive node.\n",
    "    for w in range(dnad.numWinds):      \n",
    "        G = simplify_graph(dnad.nxGraphs[w], 'segid', ['CRY'])\n",
    "        listG.append(G)\n",
    "        #listNames.append('%s_%i' % (allele, w))\n",
    "\n",
    "    listNWinds.append(dnad.numWinds)\n",
    "    listLoaded.append(i)\n",
    "    print(\"= = NOTE: ...path %s DyNetAn files loaded.\" % fullPathRoot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23253a4e-3eb2-4a28-b709-61901f5bd25f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if nWarn>0:\n",
    "    print(\"= = WARNING: A total of %i entries in the Annotations file are missing their DyNetAn datasets:\" % nWarn)\n",
    "    for i in dfAnnotations.index:\n",
    "        if not i in listLoaded:\n",
    "            print(\"  ...\",dfAnnotations['DyNetAn_Path'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af95b74-0123-4dd5-8952-4b0f7973d277",
   "metadata": {},
   "outputs": [],
   "source": [
    "# = = = = Create New analysis dataframe to incorporate information from both the annotation and simulation.\n",
    "# The idea is to pass only the list of Graphs and the Analysis dataframe to subequent parts of the pipeline.\n",
    "bFirst = True\n",
    "for i,j in enumerate(listLoaded):\n",
    "    dfTemp = pd.DataFrame(np.tile(dfAnnotations.values[j],(listNWinds[i],1)), columns = dfAnnotations.columns)\n",
    "    dfTemp['Window'] = np.arange(listNWinds[i])\n",
    "    UniqueID = [ \"%s_%i\" % (dfTemp['Allele'][k], dfTemp['Window'][k]) for k in dfTemp.index ]\n",
    "    dfTemp['UniqueID'] = UniqueID\n",
    "    if bFirst:\n",
    "        bFirst=False\n",
    "        dfAnalysis = dfTemp.copy(deep=True)\n",
    "    else:\n",
    "        dfAnalysis = dfAnalysis.append(dfTemp, ignore_index=True)\n",
    "\n",
    "#dfAnalysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "071f96a8-1fa8-46d3-8988-4352f195f91b",
   "metadata": {},
   "source": [
    "## Functions for graph plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d9d47c-1b1e-4015-80fe-9298eddc21b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if fileImportPos is not None:\n",
    "    # = = = Cheat with resid by eliminating the first letter.\n",
    "    refPosList={}\n",
    "    with open(fileImportPos,'r') as fp:\n",
    "        for line in fp:\n",
    "            l=line.split()     \n",
    "            if len(l) != 3:\n",
    "                continue\n",
    "            refPosList[ l[0][1:] ] = [ float(l[1]), float(l[2]) ]\n",
    "    posNodes={}\n",
    "    for a, name in dnad.nxGraphs[0].nodes(data='name'):\n",
    "        s = dnad.nxGraphs[0].nodes[a]['segid']\n",
    "        if name[1:] in refPosList.keys():\n",
    "            pos = refPosList[name[1:]]\n",
    "            if s not in posNodes.keys():\n",
    "                posNodes[s] = []\n",
    "            posNodes[s].append(pos)\n",
    "    for k in posNodes.keys():\n",
    "        posNodes[k] = np.mean(posNodes[k],axis=0)\n",
    "    bPosSet=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f9c63d-ce1a-4b1d-9118-b9b243083b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def arrange_self_edges(G, CDS, pos):\n",
    "    \"\"\"\n",
    "    Sets on a ColumnDataSource to plot graph self-edges.\n",
    "    Runs a simplistic computation over neighbour node positions such that the edge will be oriented to lesson overlap with existint edge rays.\n",
    "    \"\"\"\n",
    "    widthWedge=np.pi/4\n",
    "    for u,v,weight in G.edges(data='weight'):\n",
    "        if u==v:\n",
    "            x = pos[u]\n",
    "            CDS.data['x'].append(x[0])\n",
    "            CDS.data['y'].append(x[1])\n",
    "            vec = x - np.mean([pos[w] for w in G.neighbors(u)],axis=0)\n",
    "            a = np.arctan2(vec[1],vec[0])\n",
    "            CDS.data['a1'].append(a-widthWedge)\n",
    "            CDS.data['a2'].append(a+widthWedge)\n",
    "            CDS.data['weight'].append( weight )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c5fcca-db79-4609-8736-69b47e0f694a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_copy_without_self_edges(G):\n",
    "    outG = G.copy()\n",
    "    for n in outG.nodes():\n",
    "        if (n,n) in outG.edges():\n",
    "            outG.remove_edge(n,n)\n",
    "    return outG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "074503f2-c248-4be4-997d-6f1eabcb29eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_node_data_range(G, nodeAttr):\n",
    "    vals = [ G.nodes[x][nodeAttr] for x in G.nodes() ]\n",
    "    return np.min(vals), np.max(vals)\n",
    "\n",
    "def get_node_color_label_map(G):\n",
    "    vals = [ x for x in G.nodes() ]\n",
    "    _, i = np.unique(vals, return_index=True)\n",
    "    vMap=np.array([ vals[x] for x in np.sort(i)])\n",
    "    return vMap\n",
    "\n",
    "def format_graph_nodes_by_palette(G, palette, nullColour='#FFFFFF'):\n",
    "    # Set the node properties as additional entries in the graph.\n",
    "    # Should I wrap palette around for text encodings that has more types than the number of colours in palette\n",
    "    pMax = len(palette)\n",
    "    nodeColors={}\n",
    "    vMap=get_node_color_label_map(G)\n",
    "    \n",
    "    for n in G.nodes():\n",
    "        i = np.where(vMap==n)[0][0]\n",
    "        if i>=pMax:\n",
    "            nodeColors[n] = nullColour\n",
    "        else:\n",
    "            nodeColors[n] = palette[ i ]\n",
    "    nx.set_node_attributes(G, nodeColors, \"node_color\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb40f51-7893-4d99-a698-f2d180a9ea7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "colourPaletteCat = ['#FF0000'] + list( bokehPalettes.Colorblind[8] ) + ['#666666']\n",
    "for gg in listG:\n",
    "    format_graph_nodes_by_palette(gg, colourPaletteCat)\n",
    "#format_graph_edges_by_palette(G, colourPaletteLin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38c6b51-99ad-4c7c-9e3e-89377624a38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rescale_linear(dMin=0, dMax=1):\n",
    "    r = dict(min=dMin,max=dMax)\n",
    "    vfunc = \"\"\"\n",
    "        const norm = new Float64Array(xs.length)\n",
    "        const min = Math.min(...xs)\n",
    "        const max = Math.max(...xs)\n",
    "        for (let i = 0; i < xs.length; i++) {\n",
    "            norm[i] = r.min + (xs[i]-min)*(r.max-r.min)/(max-min)\n",
    "        }\n",
    "        return norm\n",
    "    \"\"\"\n",
    "    return bokehModels.CustomJSTransform(args=dict(r=r), v_func=vfunc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f3e05b-c1bf-4c16-a81f-417797fcac86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_JS_update_visibility(sourceTable, dictRenderer, dictGlyph, targetPlot):\n",
    "    \"\"\"\n",
    "    This Javascript snippet updates which of the graphs elements are visible depending on the selection in the source widget.\n",
    "    \"\"\"\n",
    "    return bokehModels.CustomJS(args=dict(s=sourceTable, dR=dictRenderer, dG=dictGlyph, pTo=targetPlot),\n",
    "        code=\"\"\"\n",
    "        var inds = cb_obj.indices ;\n",
    "        var listSelected = [] ;\n",
    "        \n",
    "        for (var i = 0; i < inds.length; i++) {\n",
    "            listSelected.push( s.data['items'][inds[i]] )\n",
    "        }\n",
    "        \n",
    "        // Note: dict uses \"X in Y\" notation, while arrays use X.includes(Y) notation.\n",
    "        for (let k in dR) {\n",
    "            if (listSelected.includes(k)) {\n",
    "                dR[k].visible = true\n",
    "            } else {\n",
    "                dR[k].visible = false\n",
    "            }\n",
    "        }\n",
    "        for (let k in dG) {\n",
    "            if (listSelected.includes(k)) {\n",
    "                dG[k].visible = true\n",
    "            } else {\n",
    "                dG[k].visible = false\n",
    "            }\n",
    "        }\n",
    "        pTo.change.emit();\n",
    "    \"\"\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6439dd9-4c6e-4cc5-8e24-c28b6c7c898e",
   "metadata": {},
   "source": [
    "## Graph-based plotting within Bokeh part A\n",
    "Initial overview render to visually confirm that simulations have  similar coarse-grained networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d725702-0d07-47e7-991b-9f72d3d788f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVE\n",
    "#output_file('Sample_Application.html',mode='inline',root_dir=None)\n",
    "output_notebook()\n",
    "\n",
    "# = = = = = = = = = = = = = = = = = = = = = = = = = = =\n",
    "# = = General settings.\n",
    "# = = = = = = = = = = = = = = = = = = = = = = = = = = =\n",
    "plotWidth=800 ; plotHeight=600\n",
    "\n",
    "# = = = = = = = = = = = = = = = = = = = = = = = = = = =\n",
    "# = = Graph\n",
    "# = = = = = = = = = = = = = = = = = = = = = = = = = = =\n",
    "\n",
    "colorsA = np.flip(bokehPalettes.YlOrRd[9])\n",
    "mapperA = bokehModels.LinearColorMapper(palette=colorsA, low=0, high=1)\n",
    "colorsB = np.flip(bokehPalettes.Blues[9])\n",
    "mapperB = bokehModels.LinearColorMapper(palette=colorsB, low=0, high=1)\n",
    "\n",
    "# = = = Plot Prep\n",
    "figA = bokehPlotting.figure(plot_width=plotWidth, plot_height=plotHeight,\n",
    "              tools=[\"pan\",\"wheel_zoom\", \"tap\", \"reset\", \"save\"],\n",
    "              title=\"Overview\")\n",
    "figA.toolbar.active_scroll = figA.select_one(bokehModels.WheelZoomTool)\n",
    "figA.title.text = \"Coarse-grained network overview\"\n",
    "\n",
    "# = = = Plot all graphs elements but hide them dynamically based on tabel selection!\n",
    "dictGraphMain = {} ; dictGraphSelfEdge = {}\n",
    "\n",
    "for i in dfAnalysis.index:\n",
    "    G   = listG[i]\n",
    "    key = dfAnalysis['UniqueID'][i]\n",
    "    \n",
    "    # = = = Plot main part of the graph without self edges.\n",
    "    Gplot = return_copy_without_self_edges(G)\n",
    "    rendererGraph = bokehPlotting.from_networkx(Gplot, posNodes, scale=2, center=(0, 0))\n",
    "    rendererGraph.node_renderer.glyph = bokehModels.Circle(size=bokehTransform.transform('count',rescale_linear(10,20)),\n",
    "                                                           fill_color='node_color'\n",
    "                                                          )\n",
    "    rendererGraph.edge_renderer.glyph = bokehModels.MultiLine(line_color='black',\n",
    "                                                              line_alpha=0.8,\n",
    "                                                              line_width=bokehTransform.transform('weight',rescale_linear(1,5))\n",
    "                                                             )\n",
    "    rendererGraph.node_renderer.selection_glyph = bokehModels.Circle(size=20, fill_color='node_color')\n",
    "    #sourceGraph = rendererGraph.node_renderer.data_source\n",
    "    \n",
    "    # = = = Plot self-edge part of the graph.\n",
    "    sourceSelfEdge = bokehModels.ColumnDataSource(data=dict(x=[], y=[], a1=[], a2=[], weight=[]))\n",
    "    #glyphSelfEdge = bokehModels.Circle(x=\"x\", y=\"y\", size=30, fill_alpha=0.0,\n",
    "    #                                     line_color='grey', line_alpha=0.8, line_width=1)\n",
    "    glyphSelfEdge = bokehModels.AnnularWedge(x=\"x\", y=\"y\", inner_radius=0, outer_radius=20, outer_radius_units='screen',\n",
    "                                             start_angle=\"a1\", end_angle=\"a2\", fill_alpha=0.0,\n",
    "                                             line_color='grey',\n",
    "                                             line_alpha=0.8,\n",
    "                                             line_width=bokehTransform.transform('weight',rescale_linear(1,5))\n",
    "                                            )\n",
    "    arrange_self_edges(G, sourceSelfEdge, rendererGraph.layout_provider.graph_layout)\n",
    "    \n",
    "    \n",
    "    # = = = Add these renderes to the figure\n",
    "    rendererSelfEdges = figA.add_glyph(sourceSelfEdge, glyphSelfEdge)\n",
    "    rendererSelfEdges.visible=True\n",
    "    figA.renderers.append(rendererGraph)\n",
    "    rendererGraph.visible=True\n",
    "    \n",
    "    dictGraphMain[key]     = rendererGraph\n",
    "    dictGraphSelfEdge[key] = rendererSelfEdges\n",
    "\n",
    "# = = = = = = = = = = = = = = = = = = = = = = =\n",
    "# = = = Additional bells and whistles\n",
    "# = = = = = = = = = = = = = = = = = = = = = = =\n",
    "\n",
    "# = = = Colour Bar\n",
    "colourList = get_node_color_label_map(G)\n",
    "palette = colourPaletteCat\n",
    "if len(colourList) > len(palette):\n",
    "    colourList = colourList[:len(palette)]\n",
    "elif len(palette) > len(colourList):\n",
    "    palette = colourPaletteCat[:len(colourList)]\n",
    "colourMapper = bokehModels.mappers.CategoricalColorMapper(palette=palette, factors=colourList)\n",
    "colourBar = bokehModels.ColorBar(name='SegID', color_mapper=colourMapper, label_standoff=12)\n",
    "figA.add_layout(colourBar, 'right')    \n",
    "\n",
    "# = = = Hover Tools\n",
    "listTemp = [ dictGraphMain[k].edge_renderer for k in dictGraphMain.keys() ] + [ dictGraphSelfEdge[k] for k in dictGraphSelfEdge.keys() ]\n",
    "edge_hover_tool = bokehModels.HoverTool(tooltips=[(\"weight\", \"@weight\")], renderers=listTemp )\n",
    "figA.add_tools(edge_hover_tool)\n",
    "\n",
    "listTemp = [ dictGraphMain[k].node_renderer for k in dictGraphMain.keys() ]\n",
    "node_hover_tool = bokehModels.HoverTool(tooltips=[(\"index\", \"@index\")], renderers=listTemp)\n",
    "figA.add_tools(node_hover_tool)\n",
    "#p.add_tools(bokehModels.HoverTool(tooltips=tooltips, renderers=[rendererA,rendererB]))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5121adf9-27b7-4818-ad7c-55602ce646de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# = = = Controls for allele comparison.\n",
    "dataTable = dict(items=[ dfAnalysis['UniqueID'][k] for k in dfAnalysis.index ])\n",
    "sourceTable = bokehModels.ColumnDataSource(dataTable)\n",
    "colsTable = [ bokehModels.TableColumn(field=\"items\", title=\"Select Dataset\") ]\n",
    "\n",
    "tableData = bokehModels.DataTable(source=sourceTable, columns=colsTable, index_position=None,\n",
    "                                  width=100, sizing_mode='stretch_height')\n",
    "\n",
    "# = = = Hookup to update visibility\n",
    "tableData.source.selected.js_on_change(\"indices\",\n",
    "                                       create_JS_update_visibility(sourceTable, dictGraphMain, dictGraphSelfEdge, figA)\n",
    "                                      )\n",
    "#graphRenderer.node_renderer.data_source.selected.js_on_change(\"indices\", callbackBig)\n",
    "#widgetSelect = bokehModels.Select(title=\"Option:\", value=\"foo\", options=[\"foo\", \"bar\", \"baz\", \"quux\"],\n",
    "#                            sizing_mode='stretch_height')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c09aecd-5829-40fc-92fc-951994dca98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "layout=bokehModels.Row(tableData, figA)\n",
    "\n",
    "show(layout)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec70cd2-8919-46d9-ac89-9e2709c47117",
   "metadata": {},
   "source": [
    "## Compare individual edges between all simulations.\n",
    "The first half uses Bokeh for graph-based depictions, e.g. of differences.\n",
    "The second half uses a Pandas data frame to utilise its box metric functionalities."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35973c1f-eb35-44d2-9242-e43e55a7e48a",
   "metadata": {},
   "source": [
    "### Numerical and statistical plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e6b839-40c1-438d-a405-d141d8aa0ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#= = = This is the first important part. Which graph metric to \n",
    "edgePair=('ND1','ND2')\n",
    "sourceEdge = bokehModels.ColumnDataSource(data=dict(cat=[], val=[]))\n",
    "#= = = This is the second important part. How to group \n",
    "#sortingField = dfAnalysis['Allele'] \n",
    "sortingField = dfAnalysis['Functional_Category']\n",
    "for i in dfAnalysis.index:\n",
    "    G = listG[i] ; key = dfAnalysis['UniqueID'][i]\n",
    "    sourceEdge.data['cat'].append( sortingField[i] )\n",
    "    sourceEdge.data['val'].append( G.edges[edgePair]['weight'] )\n",
    "listCategories=sortingField.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a298848-6c7c-4fb7-a062-db59a3c8bd2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(dict(cat=sourceEdge.data['cat'],\n",
    "                       val=sourceEdge.data['val']))\n",
    "# find the quartiles and IQR for each category\n",
    "groups = df.groupby('cat', sort=False)\n",
    "q0 = groups.quantile(q=0.00)\n",
    "q1 = groups.quantile(q=0.25)\n",
    "q2 = groups.quantile(q=0.50)\n",
    "q3 = groups.quantile(q=0.75)\n",
    "q4 = groups.quantile(q=1.0)\n",
    "iqr = q3 - q1\n",
    "upper = q3 + 1.5*iqr\n",
    "lower = q1 - 1.5*iqr\n",
    "\n",
    "# assume no outliers, shrink lengths of stems to be no longer than the minimums or maximums\n",
    "upper.val = [min([x,y]) for (x,y) in zip(list(q4.loc[:,'val']),upper.val)]\n",
    "lower.val = [max([x,y]) for (x,y) in zip(list(q0.loc[:,'val']),lower.val)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180bf137-53f9-4b55-a15c-f2d9a5d54b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# = = = General numbers like percentiles.\n",
    "groups['val'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e719d02-37dd-48e2-8965-77e2e5b37567",
   "metadata": {},
   "source": [
    "## Make box-plots as an overall visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222a8a41-13cf-4e1f-bb7e-c4d7005bae63",
   "metadata": {},
   "outputs": [],
   "source": [
    "widthBox=0.7\n",
    "widthWhisker=0.2\n",
    "plotWidth=np.max( (500,60*listCategories.shape[0]) )\n",
    "plotHeight=500\n",
    "\n",
    "listCounts = [ i for i in groups['val'].count() ]\n",
    "labelsXAxis = [ (x,\"N=%i\"%i) for x,i in zip(listCategories,listCounts)]\n",
    "\n",
    "figB = bokehPlotting.figure(plot_width=plotWidth, plot_height=plotHeight,\n",
    "              tools=[\"pan\",\"wheel_zoom\", \"tap\", \"reset\", \"save\"],\n",
    "              title=\"Overview\",\n",
    "              x_range=bokehModels.FactorRange(*labelsXAxis),\n",
    "              y_axis_label=\"%s - %s\" % edgePair)\n",
    "figB.toolbar.active_scroll = figA.select_one(bokehModels.WheelZoomTool)\n",
    "figB.title.text = \"Cross graph comparisons\"\n",
    "figB.xgrid.grid_line_color = None\n",
    "figB.xaxis.group_label_orientation = \"vertical\"\n",
    "#figB.ygrid.grid_line_color = None\n",
    "figB.ygrid.grid_line_dash = [3,3]\n",
    "figB.ygrid.minor_grid_line_color = \"lightgrey\"\n",
    "figB.ygrid.minor_grid_line_dash = [1,5]\n",
    "\n",
    "# stems\n",
    "figB.segment(listCategories, upper.val, listCategories, q3.val, line_color=\"grey\")\n",
    "figB.segment(listCategories, lower.val, listCategories, q1.val, line_color=\"grey\")\n",
    "\n",
    "# boxes\n",
    "figB.vbar(listCategories, widthBox, q2.val, q3.val, fill_alpha=0.0, line_color=\"grey\")\n",
    "figB.vbar(listCategories, widthBox, q1.val, q2.val, fill_alpha=0.0, line_color=\"grey\")\n",
    "\n",
    "# whiskers (almost-0 height rects simpler than segments)\n",
    "figB.rect(listCategories, lower.val, widthWhisker, 0.01, line_color=\"grey\")\n",
    "figB.rect(listCategories, upper.val, widthWhisker, 0.01, line_color=\"grey\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53b6743-e651-4103-a128-9aae7a6985af",
   "metadata": {},
   "outputs": [],
   "source": [
    "figB.scatter(source=sourceEdge,\n",
    "             x=bokehTransform.jitter('cat', 0.1, mean=0, distribution='normal', range=figB.x_range),\n",
    "             y='val',\n",
    "             size=6, fill_color='#BBCCFF', line_color='black'\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1d1f9b-6dee-4285-bfbe-750cbec9a28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "show(figB)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cda76ce-c2f6-4c80-8db3-a4b47289719f",
   "metadata": {},
   "source": [
    "## Normality tests for statistical comparisons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f86cbf5-ca64-4d8d-b914-cde4661f1cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#groups['val'].aggregate(np.mean)\n",
    "#groups['val'].aggregate([np.mean,'mean'])\n",
    "#groups['val'].transform(lambda x: (x - x.mean())/x.std())\n",
    "# Note: All statistical tests of normality have low power with small samples sizes,\n",
    "# i.e. false-negative rate is quite high. Small datasets needs to be quite abnormal for it to fail.\n",
    "def test_normality_shapiro(x):\n",
    "    \"\"\"\n",
    "    Suggested reading: https://stats.stackexchange.com/questions/13983/is-it-meaningful-to-test-for-normality-with-a-very-small-sample-size-e-g-n\n",
    "    Says N=20~30 needed for Shapiro to reliably reject an exponential versus a normal distribution.\n",
    "    \"\"\"\n",
    "    r = sp.stats.shapiro(x)\n",
    "    return r[1]>0.05\n",
    "\n",
    "def test_normality_dagostino(x):\n",
    "    \"\"\"\n",
    "    Minimum 8 samples.\n",
    "    \"\"\"\n",
    "    r = sp.stats.normaltest(x)\n",
    "    return r[1]>0.05\n",
    "\n",
    "def test_normality_anderson(x):\n",
    "    \"\"\"\n",
    "    Minimum 4 samples? Otherwise auto-False. Also is probably Auto-True for N=4~6.\n",
    "    \"\"\"\n",
    "    r = sp.stats.anderson(x)\n",
    "    # Significance levels: 15, 10, 5, 2.5, 1\n",
    "    # r.significance_level[i] \n",
    "    return [ r.statistic < r.critical_values[i] for i in range(len(r.critical_values)) ]\n",
    "\n",
    "def test_similarity_ttest(x1, x2, bSameVariance=False):\n",
    "    \"\"\"\n",
    "    Assumes normal distribution of data.\n",
    "    True uses the independent 2-sample t-test (Student's)\n",
    "    False uses Welch's T-test.\n",
    "    \"\"\"\n",
    "    r = sp.stats.ttest_ind(x1, x2, equal_var=bSameVariance)\n",
    "    return r[1]>0.05\n",
    "    \n",
    "def test_similiarity_mannwhitneyu(x1, x2):\n",
    "    \"\"\"\n",
    "    Does not assumes normal distribution of data, or similarity of variances.\n",
    "    Assumes rank-order ability.\n",
    "    \"\"\"\n",
    "    r = sp.stats.mannwhitneyu(x1,x2)\n",
    "    return r[1]>0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e95c08b-fd43-4ecb-b20f-b89bd0cfaaf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#groups['val'].aggregate([test_normality_shapiro,test_normality_dagostino,test_normality_anderson])\n",
    "dfNormalityTest = groups['val'].aggregate([test_normality_shapiro,test_normality_anderson]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79fb7fd6-74c5-4dc7-a402-d2254c837935",
   "metadata": {},
   "outputs": [],
   "source": [
    "sourceNormal    = bokehModels.ColumnDataSource(data=dict(cat=[]))\n",
    "sourceNotNormal = bokehModels.ColumnDataSource(data=dict(cat=[]))\n",
    "for i,k in enumerate(dfNormalityTest.index):\n",
    "    if np.all( dfNormalityTest.values[i][1]+[dfNormalityTest.values[i][0]] ):\n",
    "        sourceNormal.data['cat'].append( k )\n",
    "    else:\n",
    "        sourceNotNormal.data['cat'].append( k )\n",
    "\n",
    "dfNormalityTest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab04c08-d459-49d5-91f9-4f7e92baab9c",
   "metadata": {},
   "source": [
    "### Comparison tests to see if groups a significantly different from each other. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c98b0b-1ca4-48e7-a7b7-37906b6ee2f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dictIndices = groups['val'].indices\n",
    "sourceSimilar = bokehModels.ColumnDataSource(data=dict(catA=[], catB=[]))\n",
    "sourceDissimilar = bokehModels.ColumnDataSource(data=dict(catA=[], catB=[]))\n",
    "#keyIndex = {}\n",
    "#for i, k in enumerate(dictIndices.keys()):\n",
    "#    keyIndex[k]=i\n",
    "#nKeys = len(dictIndices)\n",
    "# matSimilarity = np.zeros( (nKeys,nKeys), dtype=bool)\n",
    "for k1,k2 in combinations( dictIndices.keys(), 2 ):\n",
    "    s1 = df['val'][ groups['val'].indices[k1] ]\n",
    "    s2 = df['val'][ groups['val'].indices[k2] ]\n",
    "    if np.all( (test_similarity_ttest(s1, s2), test_similiarity_mannwhitneyu(s1, s2)) ):\n",
    "        sourceSimilar.data['catA'].append( k1 )    ; sourceSimilar.data['catB'].append( k2 )\n",
    "    else:\n",
    "        sourceDissimilar.data['catA'].append( k1 ) ; sourceDissimilar.data['catB'].append( k2 )\n",
    "    #matSimilarity[ keyIndex[k2],keyIndex[k1] ] = matSimilarity[ keyIndex[k1],keyIndex[k2] ] = np.all( (test_similarity_ttest(s1, s2), test_similiarity_mannwhitneyu(s1, s2)) )\n",
    "    #print( k1, k2, (test_similarity_ttest(s1, s2), test_similiarity_mannwhitneyu(s1, s2)) )\n",
    "\n",
    "# = = = Estimate error rate. Expect 5% to come up.\n",
    "ratioSim = len(sourceDissimilar.data['catA'])/len(sourceSimilar.data['catA'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8efcf805-aeaf-4dc3-9323-fbfb0cd14cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# = = = Plot similarity matrix.\n",
    "plotWidth=plotHeight=np.max( (500,50*listCategories.shape[0]) )\n",
    "figC = bokehPlotting.figure(plot_width=plotWidth, plot_height=plotHeight,\n",
    "              tools=[\"tap\", \"reset\", \"save\"],\n",
    "              title=\"Overview\",\n",
    "              x_range=listCategories, y_range=[l for l in reversed(listCategories)] )\n",
    "\n",
    "figC.toolbar.active_scroll = figA.select_one(bokehModels.WheelZoomTool)\n",
    "figC.title.text = \"Normality/pairwise-similarity tests (p>0.05 per test). %.1f%% of pairs are not similar.\" % (ratioSim*100)\n",
    "figC.xgrid.grid_line_color = None\n",
    "figC.ygrid.grid_line_color = None\n",
    "figC.xaxis.major_label_orientation = \"vertical\"\n",
    "\n",
    "propGlyphs=dict( size=12, line_alpha=1.0, line_color='black')\n",
    "                #size_units='data')\n",
    "figC.scatter(x='catA',y='catB',source=sourceSimilar, fill_color='blue', marker='plus', legend_label='Passes all similarity tests.', **propGlyphs)\n",
    "figC.scatter(x='catA',y='catB',source=sourceDissimilar, fill_color='yellow', marker='triangle', legend_label='Fails 1+ similiarity test.', **propGlyphs)\n",
    "figC.scatter(x='cat',y='cat',source=sourceNormal, fill_color='green', marker='plus',  legend_label='Passes all normality tests.', **propGlyphs)\n",
    "figC.scatter(x='cat',y='cat',source=sourceNotNormal, fill_color='pink', marker='triangle', legend_label='Fails 1+ normality test.', **propGlyphs)\n",
    "\n",
    "hoverTool = bokehModels.HoverTool(tooltips=[(\"a\", \"@catA\"),(\"b\", \"@catB\")], point_policy='snap_to_data')\n",
    "figC.add_tools(hoverTool)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59cf6b01-3ff0-49e7-bcfb-0c792b9170c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "show(figC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de40abf1-b66e-46a5-93f9-477ba0b699bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
