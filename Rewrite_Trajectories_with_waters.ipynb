{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "290bbf0b-05ca-446d-88d8-0cf5cc12a81a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import numpy as np\n",
    "import MDAnalysis as mda\n",
    "from MDAnalysis.analysis.base import AnalysisFromFunction\n",
    "from MDAnalysis.coordinates.memory import MemoryReader\n",
    "from MDAnalysis.analysis.distances import distance_array\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab4d8ee-d764-4768-938d-94772e223a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bPythonScriptExport=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2593d6de-06a0-46cb-9b14-93f81b2a345b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if bPythonScriptExport:\n",
    "    import argparse\n",
    "    parser = argparse.ArgumentParser(description='Analyse a system trajectory and match solvent molecules to cluster sites, '\n",
    "                                                 'using sets of residues within X Angs as the site definitons, and '\n",
    "                                                 'occupancy rates to rank water additions.',\n",
    "                                                 formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n",
    "    parser.add_argument('--top', type=str, dest='topologyFile', default='seg.psf',\n",
    "                        help='The name of the protein structure file.')\n",
    "    parser.add_argument('--trj', type=str, dest='trajectoryFile', default='sum.xtc',\n",
    "                        help='The name of the trajectory file.')\n",
    "    parser.add_argument('--clust', type=str, dest='clustDefFile', default='cluster_definitions.txt',\n",
    "                        help='The name of the cluster definitions file. Can be fed from calculate_contact_persistence.py. '\n",
    "                             'Although only resids are currently being read in, the expected file format is:\\n'\n",
    "                             '0 Intersection: <segid:resid1> <segid:resid2> ...\\n'\n",
    "                             '0 Union: <segid:resid1> <segid:resid2> ...\\n'                       \n",
    "                             '1 Intersection: <segid:resid1> <segid:resid2> ...\\n'\n",
    "                             '1 Union: <segid:resid1> <segid:resid2> ...\\n'\n",
    "                             '...\\n')\n",
    "    parser.add_argument('-n', '--n_clust', type=int, dest='numCluster', default=None,\n",
    "                        help='Consider only the top N clusters read in the file. If not given, compute for all clusters read.')    \n",
    "    parser.add_argument('-d', type=float, dest='distCutoff', default=3.5,\n",
    "                        help='Maximum separation for pairs to be considered in contact. Needs to match the value defined for clustering.')\n",
    "    parser.add_argument('--out', type=str, dest='outputPrefix', default='clustered',\n",
    "                        help='A prefix for all output files generated.')\n",
    "    parser.add_argument('--sel_site', type=str, dest='selectionTextSite', default='name OW and resname SOL',\n",
    "                        help='An MDAnalysis selection text that refers to the atoms by which clustering was conducted. '\n",
    "                       'Examples: \"name CL\" and \"name OW and resname SOL\".')    \n",
    "    parser.add_argument('--sel_host', type=str, dest='selectionTextHost', default='protein',\n",
    "                        help='An MDAnalysis selection text that chooses the host solute by which clustering was conducted.')    \n",
    "    parser.add_argument('--sel_solvent', type=str, dest='selectionTextSolvent', default='resname SOL',\n",
    "                        help='(Output) An MDAnalysis selection text that chooses the solvents to create a universe for.')\n",
    "    parser.add_argument('--sel_system', type=str, dest='selectionTextSystem', default=None,\n",
    "                        help='(Output) An MDAnalysis selection text that chooses atoms from the host system to include iin the output.'\n",
    "                        'If not given, then only the cluster solvent atoms are written.')\n",
    "    parser.add_argument('--in_mem', action='store_true', dest='bInMemory',\n",
    "                        help='Asks MDAnlaysis to load the entire trajectory into memory.')\n",
    "    args = parser.parse_args()\n",
    "    \n",
    "    #ratioCutoff  = args.ratioCutoff\n",
    "    topFile      = args.topologyFile\n",
    "    trjFile      = args.trajectoryFile\n",
    "    clustDefFile = args.clustDefFile\n",
    "    nClusts      = args.numCluster\n",
    "    distCutoff   = args.distCutoff\n",
    "    \n",
    "    outputPrefix = args.outputPrefix\n",
    "\n",
    "    seltxtSite   = args.selectionTextSite\n",
    "    seltxtHost   = args.selectionTextHost\n",
    "    seltxtSolv   = args.selectionTextSolvent\n",
    "    seltxtSyst   = args.selectionTextSystem\n",
    "    bInMemory    = args.bInMemory    \n",
    "    MDAbackend   = 'serial'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c76e3502-6076-4ce0-8e2b-bd1736587ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not bPythonScriptExport:\n",
    "    %cd ..\n",
    "    allele='N1303K' ; temperature='310K' ; repl=3\n",
    "    workDir = './trajectories/%s/%s/%i' % (allele, temperature, repl)\n",
    "    topFile      = os.path.join(workDir, 'seg.psf')\n",
    "    trjFile      = os.path.join(workDir, 'sum.xtc')\n",
    "    clustDefFile = 'Stable_Solvent_Clustering.cluster_definitions_d3.5_r0.50.txt'\n",
    "    distCutoff   = 3.5\n",
    "    \n",
    "    #outputPrefix = os.path.join(workDir, 'clustered')\n",
    "    outputPrefix = os.path.join(workDir, 'clustered_d3.5_r0.50')\n",
    "    \n",
    "    seltxtSite   = \"name OW\"\n",
    "    seltxtHost   = \"protein\"\n",
    "    seltxtSolv   = \"resname SOL\"\n",
    "    seltxtSyst   = \"(protein or resname ATP MG) and not name MN? 1MN? 2MN? 1MC? 2MC?\"\n",
    "    bInMemory    = True\n",
    "    nClusts      = 33\n",
    "    MDAbackend   = 'openMP'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e01b9f0-3442-459d-b2da-8cff0a68129a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# = = = Optional modules for profiling. Move to after argparse to prevent it from reporting when -h is invoked.\n",
    "try:\n",
    "    import psutil\n",
    "    print( \"= = psutil module installed. Will report memory use.\")\n",
    "    def get_memory_use():\n",
    "        proc = psutil.Process(os.getpid())\n",
    "        mem = proc.memory_info().rss/2**20\n",
    "        print( \"= = Current memory footprint @ %s : %.3f MiB\" % (time.ctime(), mem) )\n",
    "except ModuleNotFoundError:\n",
    "    print( \"= = psutil module not installed. Will not report memory use.\")\n",
    "    def get_memory_use():\n",
    "        return\n",
    "try:\n",
    "    from tqdm.auto import tqdm\n",
    "    print( \"= = tdqm module installed. Will report loop progress.\")\n",
    "except ModuleNotFoundError:\n",
    "    print( \"= = tdqm module not installed. Will not report loop progress.\")    \n",
    "    def tdqm(f):\n",
    "        return f\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6644fe5-b85a-429b-9aa4-ab1907b1c5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_list_items( ll ):\n",
    "    for l in ll:\n",
    "        l[0].sort()\n",
    "        for item in l[0]:\n",
    "            if item in l[1]:\n",
    "                l[1].remove(item)\n",
    "        l[1].sort()\n",
    "    \n",
    "#0 Intersection: ND1:573 ND1:603 ND1:464 ND1:465 ND1:572\n",
    "#0 Union: ND1:573 ND1:603 ND1:464 ND1:465 ND1:572 ND2:1348 ND1:493\n",
    "#1 Intersection: ND1:549 ND2:1251 ND1:550\n",
    "#1 Union: ND2:1370 ND1:549 ND1:551 ND2:1371 ND1:553 ND1:548 ND2:1251 ND1:550 ND2:1291\n",
    "#2 Intersection: LAS:28 TD2:1032 TD2:1036 TD2:1033 LAS:24\n",
    "#2 Union: TD2:1037 TD2:1032 TD2:1036 LAS:27 LAS:24 LAS:28 TD2:1034 TD2:1033 TD2:1035 LAS:25                                                                    3\n",
    "#...\n",
    "def read_cluster_definitions(fileName):\n",
    "    out=[]\n",
    "    items=[]    \n",
    "    with open(fileName,'r') as fp:\n",
    "        for line in fp:\n",
    "            l=line.split()\n",
    "            if len(l)<2:\n",
    "                continue\n",
    "            elif len(l)==2:\n",
    "                items.append([])\n",
    "            else:\n",
    "                temp=[]\n",
    "                for i in range(2,len(l)):\n",
    "                    temp.append( int(l[i].split(':')[-1]) )\n",
    "                items.append(temp)\n",
    "            if len(items)==2:\n",
    "                out.append(items)\n",
    "                items=[]\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7664ce1b-cf9a-4696-a271-d0d5b58e3a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_list(l, pref=\"\", suff=\"\", sep=\" \"):\n",
    "    out=\"\"\n",
    "    for item in l:\n",
    "        out+=\"%s%s%s\" % (pref, item, suff)\n",
    "        if item != l[-1]:\n",
    "            out+=sep\n",
    "    return out\n",
    "\n",
    "def write_cluster_selection_text(l, selSite=\"name OW\", selSolute=\"protein\", d=5.0):\n",
    "    out=[]\n",
    "    for i in l:\n",
    "        s1=parse_list(i[0], pref=\"(around %g (resid \" % d, suff=\" and %s))\" % selSolute, sep=\" and \")\n",
    "        if s1 !=\"\":\n",
    "            s1+=\" and \"\n",
    "        s2 = parse_list(i[1], pref=\"\", sep=\" \")\n",
    "        s2b = \"(around %g (resid %s and protein))\" % (d, s2)\n",
    "        out.append(\"%s and %s %s\" % (selSite, s1, s2b))\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dca27f2-7de1-46a7-9444-ea08bd14fe13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_subuniverse_inmem(u, selectionText):\n",
    "    a = u.select_atoms(selectionText)\n",
    "    return mda.Merge(a).load_new(AnalysisFromFunction(lambda ag: ag.positions.copy(), a).run().results, format=MemoryReader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f55d618-40f2-4569-980f-e5d531469406",
   "metadata": {},
   "outputs": [],
   "source": [
    "selectionResids = read_cluster_definitions(clustDefFile)\n",
    "process_list_items(selectionResids) \n",
    "stringSelectionResids = [ [str(s[0]).strip('[]'),str(s[1]).strip('[]')] for s in selectionResids ]\n",
    "x = write_cluster_selection_text(selectionResids, selSite=seltxtSite, selSolute=seltxtHost, d=distCutoff)\n",
    "print(\"= = cluster definition file processed with distance cutoff %g Angs.\" % distCutoff)\n",
    "print(\"   ...selection text for cluster 0:\", x[0])\n",
    "\n",
    "if nClusts is None:\n",
    "    nClusts = len(selectionResids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971752c5-96c9-49ae-8638-a8423eab7b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "bWriteOnlyWaters=True\n",
    "if seltxtSyst is not None:\n",
    "    bWriteOnlyWaters=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e11ea71-3867-467d-a965-6514af8e77f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "bInMemory=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e09fe143-6b70-4508-9aea-6d5c6cfaa934",
   "metadata": {},
   "outputs": [],
   "source": [
    "u = mda.Universe(topFile,trjFile, in_memory=False)\n",
    "nFrames=u.trajectory.n_frames\n",
    "if bInMemory:\n",
    "    print(\"= = Loading the trajectories into memory for subselections %s and %s ...\" % (seltxtHost, seltxtSite) )\n",
    "    # The in_memory version loads just the protein and solvent atoms for computation of distance matrices\n",
    "    uHost  = load_subuniverse_inmem(u, seltxtHost)\n",
    "    print(\"= = Loaded host sub-universe with %i atoms. Memory of loaded trajectory: %i MiB\" % (uHost.trajectory.n_atoms, sys.getsizeof(uHost.trajectory.coordinate_array)/2**20 ) )\n",
    "    uSite  = load_subuniverse_inmem(u, seltxtSite)\n",
    "    print(\"= = Loaded site sub-universe with %i atoms. Memory of loaded trajectory: %i MiB\" % (uSite.trajectory.n_atoms, sys.getsizeof(uSite.trajectory.coordinate_array)/2**20 ) )\n",
    "get_memory_use()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed008e6e-4ac3-430c-91e1-e476b69ff79b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if bInMemory:\n",
    "    indexSelectionResids = []\n",
    "    for selClust in selectionResids:\n",
    "        # Each residue in the intersect selection needs its own list of indices for slicing.\n",
    "        # The whole residue in the union selection is added in a single set of incides for slicing.\n",
    "        temp = [ uHost.select_atoms(\"resid %i\" % r).indices for r in selClust[0] ]\n",
    "        if len(selClust[1])>0:\n",
    "            temp.append( uHost.select_atoms(\"resid %s\" % ' '.join(map(str,selClust[1])) ).indices )\n",
    "        indexSelectionResids.append( temp )\n",
    "else:\n",
    "    listAtomSels = []\n",
    "    for i in range(nClusts):\n",
    "        listAtomSels.append( u.select_atoms(x[i], updating=True, periodic=False) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66eb27b-7f38-4057-9be9-acd30362c77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "atomSelSite=u.select_atoms(seltxtSite)\n",
    "nSites = atomSelSite.n_atoms\n",
    "dictGlobalIndex = { a:b for a,b in enumerate(atomSelSite.indices) }\n",
    "drevGlobalIndex = { b:a for a,b in dictGlobalIndex.items()}    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3fc1961-8de1-4303-a5b1-5d9b44e5628e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The matBoolIndices holds the information about which water ID is within the cutoffdistance from the protein residue atoms.\n",
    "One can access the fram and index information via np.where( matBoolIndices[frame,cluster,waterID] )\n",
    "\"\"\"\n",
    "print(\"= = Allocating large boolean matrix for fast computation.\")\n",
    "matBoolIndices=np.full( (nFrames, nClusts, nSites), False)\n",
    "matTemps=[]\n",
    "for i in range(nClusts):\n",
    "    nSel = len(indexSelectionResids[i])\n",
    "    matTemps.append( np.full( (nSel, nSites), False) )\n",
    "\n",
    "# = = = Profile memory use now.\n",
    "get_memory_use()\n",
    "    \n",
    "if bInMemory:\n",
    "    print(\"= = Entering lengthy distance matrix computation to determine water site occupancies...\")\n",
    "    print(\"    ...Starting at: %s\" % time.ctime() )        \n",
    "    for f in tqdm(range(nFrames)):\n",
    "        for c in range(nClusts):\n",
    "            nSel = len(indexSelectionResids[c])\n",
    "            #matTemp = np.full( (nSel, uSite.n_atoms), False)\n",
    "            matTemps[c][:] = False\n",
    "            # = = Get site atoms within X of any host atoms in sub-selection, e.g. any atom of protein resid X\n",
    "            for j in range(nSel):\n",
    "                posHost=uHost.trajectory.coordinate_array[f,indexSelectionResids[c][j]]\n",
    "                distMat = mda.analysis.distances.distance_array(posHost,\n",
    "                                                                uSite.trajectory.coordinate_array[f],\n",
    "                                                                backend=MDAbackend)\n",
    "                matTemps[c][j] = np.any( distMat<distCutoff, axis=0 )\n",
    "            # = = Filter only site atoms that are within the cutoff or all selections.\n",
    "            matBoolIndices[f,c] = np.all( matTemps[c], axis=0 )\n",
    "else:\n",
    "    print(\"= = Entering lengthy distance matrix computation to determine water site occupancies...\")\n",
    "    print(\"    ...Starting at: %s\" % time.ctime() )\n",
    "    for f in tqdm(range(nFrames)):\n",
    "        u.trajectory[f]\n",
    "        for c in range(nClusts):\n",
    "            for i in listAtomSels[c].indices:\n",
    "                matBoolIndices[f,c,drevGlobalIndex[i]]=True\n",
    "    print(\"    ...Ending at: %s\" % time.ctime() )    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68111b4f-2464-4ed9-a796-6f3241055d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print( \"= = Boolean matrix of site occupancies complete. Cleaning up sub-universes (if applicable).\")\n",
    "if bInMemory:\n",
    "    # = = Deallocation of the three largest matrices to save memory\n",
    "    matTemps = None \n",
    "    uHost.trajectory = None ; uSite.trajectory = None\n",
    "get_memory_use()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4db417a-29ae-402e-865f-6502f508aa62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.io import output_notebook, output_file, show\n",
    "from bokeh.plotting import figure\n",
    "from bokeh.layouts import row, column\n",
    "import bokeh.models as bokehModels\n",
    "import bokeh.palettes as bokehPalettes\n",
    "\n",
    "def map_palette(p, v, vMin, vMax):\n",
    "    x=int((v-vMin)/(vMax-vMin)*(len(p)-1))\n",
    "    return p[x]\n",
    "\n",
    "def create_JS_update_visibility(listGlyphs, div=\"\", divText=None):\n",
    "    return bokehModels.CustomJS(args=dict(gs=listGlyphs, d = div, dt=divText),\n",
    "             code=\"\"\"\n",
    "             //var s = this.item;\n",
    "             var s = this.value_throttled;\n",
    "             for (var i = 0; i < gs.length; i++) {\n",
    "                 if ( i == s ) {\n",
    "                     gs[i].visible = true\n",
    "                 } else if ( gs[i].visible ) {\n",
    "                     gs[i].visible = false\n",
    "                 }\n",
    "             }\n",
    "             if ( d != \"\" ) {\n",
    "                 d.text = '<strong>Core resids:</strong> ' + dt[s][0] + '<br><strong>Peripheral resids:</strong> ' + dt[s][1]\n",
    "             }\n",
    "             \"\"\"\n",
    "            )\n",
    "\n",
    "def export_site_occupancy_as_bokehHTML(outputFile,\n",
    "                                       listXs, listYs, listColours,\n",
    "                                       listClusterDefs=None,\n",
    "                                       titleText='Water occupancy',\n",
    "                                       bNoteBook=False,\n",
    "                                       palette=bokehPalettes.Viridis256\n",
    "                                      ):\n",
    "    nPlots = len(listXs)\n",
    "            \n",
    "    fig = figure(title=titleText, plot_width=800, plot_height=400,\n",
    "                 x_axis_label='Trajectory frame', y_axis_label='solvent index')\n",
    "    listSources = []\n",
    "    listGlyphs   = []\n",
    "    for i in range(nPlots):       \n",
    "        source = bokehModels.ColumnDataSource({'x': listXs[i], 'y' : listYs[i],\n",
    "                                               'color': listColours[i],\n",
    "                                              })\n",
    "        glyph = fig.scatter(x = 'x', y = 'y', size=2, color='color', source = source)          \n",
    "        listSources.append(source)\n",
    "        glyph.visible=(i==0)\n",
    "        listGlyphs.append(glyph)\n",
    "\n",
    "    colourMapper = bokehModels.mappers.LinearColorMapper(palette=palette, low=0.0, high=1.0)\n",
    "    colourBar = bokehModels.ColorBar(title='Occupancy rate',\n",
    "                                     color_mapper=colourMapper, label_standoff=12)\n",
    "    fig.add_layout(colourBar, 'above')\n",
    "\n",
    "    if listClusterDefs is None:\n",
    "        div = bokehModels.Div(width=600, text=trjFile)\n",
    "    else:\n",
    "        div = bokehModels.Div(width=600, text='<strong>Core resids:</strong> %s<br><strong>Peripheral resids:</strong> %s' % \\\n",
    "                              (listClusterDefs[0][0], listClusterDefs[0][1]))\n",
    "        \n",
    "    sliderWidget = bokehModels.Slider(width=200,title='Show cluster...', start=0, end=nClusts-1, step=1, value=0)\n",
    "    sliderWidget.js_on_change('value_throttled',\n",
    "                              create_JS_update_visibility(listGlyphs, div, listClusterDefs))\n",
    "\n",
    "    output_file(outputFile)\n",
    "    if not bPythonScriptExport:\n",
    "        output_notebook()\n",
    "    show(column(row(sliderWidget,div),fig))            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b999f5a-8353-4f63-9383-8372caa8db92",
   "metadata": {},
   "outputs": [],
   "source": [
    "listCounters=[]\n",
    "for i in range(nClusts):\n",
    "    c =  Counter( np.where(matBoolIndices[:,i])[1] )\n",
    "    print( \"Cluster %i, 5 most common waters:\" % i, c.most_common(5) )\n",
    "    listCounters.append( c )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "863546ec-aaf3-43fb-b9ae-e3b760b2ef99",
   "metadata": {},
   "outputs": [],
   "source": [
    "listAtomColours=[]\n",
    "for i in range(nClusts):\n",
    "    #c=listDictAtomData[i]['counter']\n",
    "    c=listCounters[i]\n",
    "    l=[]\n",
    "    for index in np.where(matBoolIndices[:,i])[1]:\n",
    "         l.append( map_palette( bokehPalettes.Viridis256, c[index], 0, nFrames )  )\n",
    "    listAtomColours.append( l )\n",
    "\n",
    "export_site_occupancy_as_bokehHTML( outputPrefix+'_site_occupancy_all.html',\n",
    "                                   [ np.where(matBoolIndices[:,i])[0] for i in range(nClusts) ],\n",
    "                                   [ np.where(matBoolIndices[:,i])[1] for i in range(nClusts) ],\n",
    "                                   [ listAtomColours[i] for i in range(nClusts) ],\n",
    "                                   listClusterDefs=stringSelectionResids,\n",
    "                                   titleText='Waters satisfying consensus cluster residues sets, using distance cutoff %g Angs.' % distCutoff,\n",
    "                                   bNoteBook=not bPythonScriptExport,\n",
    "                                   palette=bokehPalettes.Viridis256\n",
    "                                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cfa4ae2-6f97-41c8-8b6c-f9e4a2691f05",
   "metadata": {},
   "source": [
    "## Populate the assignment of a water molecule to every site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "375b0930-661e-4baf-9f21-d8bd09537a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_duplicate_assignments(arr, emptyID=0):\n",
    "    d=[]\n",
    "    for j in range(arr.shape[1]):\n",
    "        check = arr[np.nonzero(arr[...,j]-emptyID)[0],j]\n",
    "        if len(np.unique(check))<len(check):\n",
    "            d.append(j)    \n",
    "    print( \"...Debug: frames with duplicate assignments:\", len(d) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "024e128e-0610-4aa3-b67e-069b066a06e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def report_current_cluster_allocations(clusterAssignments, emptyID=-1):\n",
    "    sizeTotal = clusterAssignments.shape[0]*clusterAssignments.shape[1]\n",
    "    sizeAllocated = np.count_nonzero(clusterAssignments-emptyID)\n",
    "    print ( \"Assigned : missing : Total\" )\n",
    "    print ( sizeAllocated, sizeTotal - sizeAllocated, sizeTotal )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb81cff1-2b03-42cf-b551-9f1705347617",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The complete non-redundant assignment of water molecules to each cluster for each frame.\n",
    "emptyID=-1\n",
    "clusterAssignments=np.zeros((nClusts,nFrames), dtype=int)\n",
    "if emptyID != 0:\n",
    "    clusterAssignments[:]=emptyID\n",
    "\n",
    "# List of waters to be ignored as they are adjacent clusters.\n",
    "listAssigned=[]\n",
    "\n",
    "# Copy of counter lists to pop and modify as necessary.\n",
    "cTest=[]\n",
    "for i in range(nClusts):\n",
    "    cTest.append( [ (k,v) for k,v in listCounters[i].most_common() ] )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e04c017c-ad3a-4c60-bbb1-559b2cb2c3b8",
   "metadata": {},
   "source": [
    "### Step 1.\n",
    "Assign waters with maximium occupancy in each cluster. Order by clusters with higher prevalence among simulations (lowID to highID)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8adf4a7f-ad11-4546-b89e-744d44948672",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(nClusts):\n",
    "    for k, v in cTest[i]:\n",
    "        cTest[i].pop(0)\n",
    "        if k in listAssigned:\n",
    "            print(\"Water %i repeated in cluster %i\" % (k,i))\n",
    "            continue\n",
    "        listAssigned.append(k)\n",
    "        # = = = Assign the frames in where water ID k is found in cluster i\n",
    "        clusterAssignments[ i, np.where( matBoolIndices[:,i,k] )[0] ] = k\n",
    "        #for j in range(nFrames):\n",
    "        #    if k in listDictAtomData[i]['indices'][j]:\n",
    "        #        clusterAssignments[i,j] = k\n",
    "        print(\"Water %i (occ. %i) assigned to cluster %i by maximum occupancy\" % (k,v,i))\n",
    "        break\n",
    "\n",
    "rAssigned=100*np.count_nonzero(clusterAssignments-emptyID)/(nClusts*nFrames)\n",
    "print(\"   ...%.1f%% assigned so far.\" % rAssigned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f512b6d-dc56-46b6-8882-c1317cb568bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_duplicate_assignments(clusterAssignments, emptyID=-1)\n",
    "report_current_cluster_allocations(clusterAssignments, emptyID=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "460e8a67-6939-4bef-887d-3262ba110bcd",
   "metadata": {},
   "source": [
    "### Step 2.\n",
    "Starting populating the assignment matrix by working through the cluster-specific counters, ordered by highest occupancy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760a3b80-fbeb-487f-b171-2f3bec3bbc37",
   "metadata": {},
   "outputs": [],
   "source": [
    "cTest2 = np.array([ [i,k,v] for i,l in enumerate(cTest) for k,v in l ])\n",
    "cTest2 = cTest2[ np.flip(np.argsort(cTest2[...,2])) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0953b738-c2ff-4850-aff4-e518c10e9b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "minFrameBreak=0.01*nFrames\n",
    "#minFrameBreak=1\n",
    "for cID, k, v in cTest2:\n",
    "    if v<minFrameBreak:\n",
    "        break\n",
    "    if k in listAssigned:\n",
    "        #print(\"Water %i repeated in cluster %i\" % (k,cID))\n",
    "        continue\n",
    "        \n",
    "    # = = = Assign the frames in where water ID k is found in cluster i\n",
    "    # clusterAssignments[ cID, np.where( matBoolIndices[:,cID,k] )[0] ] = k \n",
    "    # Two checks are performed.\n",
    "    # - The ==emptyID checks that cluster assignments is currenty empty.\n",
    "    # - The np.any() checks that water ID k hasn't been assigned to another cluster yet in that same frame.\n",
    "    indices = np.where(np.logical_and(np.logical_and(matBoolIndices[:,cID,k],\n",
    "                                                     clusterAssignments[cID] == emptyID),\n",
    "                                                     np.all(clusterAssignments!=k,axis=0)\n",
    "                      ))[0]\n",
    "    clusterAssignments[cID, indices ] = k\n",
    "    #countOverlap=0    \n",
    "    #for j in range(nFrames):\n",
    "    #    if k in clusterAssignments[...,j]:\n",
    "    #        # = = = Preassigned to another cluster\n",
    "    #        continue\n",
    "    #    if k in listDictAtomData[cID]['indices'][j]:\n",
    "    #        if clusterAssignments[cID,j]==emptyID:\n",
    "    #            clusterAssignments[cID,j] = k\n",
    "    #        else:\n",
    "    #            countOverlap+=1\n",
    "    #if countOverlap<v:\n",
    "    #    print(\"Water %i (n: %i of %i) assigned to cluster %i by sequential fill. \" % (k,v-countOverlap,v,cID))\n",
    "    \n",
    "rAssigned=100*np.count_nonzero(clusterAssignments-emptyID)/(nClusts*nFrames)\n",
    "print(\"   ...%.1f%% assigned so far.\" % rAssigned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c86b671-adfa-4c48-bd2c-6222a039a7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_duplicate_assignments(clusterAssignments, emptyID=-1)\n",
    "report_current_cluster_allocations(clusterAssignments, emptyID=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb1ec62d-0977-43b8-822d-950100226ca4",
   "metadata": {},
   "source": [
    "### Step 3.\n",
    "After this, extend empty assignments by looking at existing populated entries on either side. Now ignoring whether the assignment is already taken."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "772f2bdc-7fbd-4f70-ae7a-fb17a0ce14ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_discrete_ranges(arr):\n",
    "    if len(arr)==0:\n",
    "        return [],[]\n",
    "    left=[] ; right=[]\n",
    "    l=arr[0] ; r=arr[0]\n",
    "    for v in arr[1:]:\n",
    "        if v==r+1:\n",
    "            r+=1\n",
    "            continue\n",
    "        left.append(l) ; right.append(r)\n",
    "        l=v ; r=v\n",
    "    left.append(l) ; right.append(r)\n",
    "    return left, right\n",
    "\n",
    "# = = = Fill in voids from existing water IDs, based on adjacency.\n",
    "for i in range(nClusts):\n",
    "    l,r = return_discrete_ranges( np.where(clusterAssignments[i]==emptyID)[0] )\n",
    "    for a,b in zip(l,r):        \n",
    "        if a==0:\n",
    "            if b==nFrames-1:\n",
    "                # Completely empty\n",
    "                continue\n",
    "            else:\n",
    "                clusterAssignments[i,a:b+1]=clusterAssignments[i,b+1]\n",
    "        elif b==nFrames-1:\n",
    "            clusterAssignments[i,a:b+1]=clusterAssignments[i,a-1]\n",
    "        else:\n",
    "            m=int(0.5*(a+b))\n",
    "            clusterAssignments[i,m:b+1]=clusterAssignments[i,b+1]            \n",
    "            clusterAssignments[i,a:m]=clusterAssignments[i,a-1]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ad9134-0086-4d30-a9b7-264d2e3ee87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_duplicate_assignments(clusterAssignments, emptyID=-1)\n",
    "report_current_cluster_allocations(clusterAssignments, emptyID=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a4c1b5-601c-4259-bdb6-83e525850d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# = = = Cleanup.\n",
    "matBoolIndices = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f8eff0-1640-4de8-aa28-1eb314ce252b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print( \"= = Cluster assignments complete. Cleaning up boolean matrix.\")\n",
    "get_memory_use()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bfb9215-0e88-47f1-ae57-6ecae180d454",
   "metadata": {},
   "source": [
    "### Plot the final assignment, taking note of duplicate assignemnts due to the final step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c1e7461-fc13-4bef-948c-e8e3ae5e7e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "colours = np.chararray(clusterAssignments.shape, itemsize=7)\n",
    "for j in range(clusterAssignments.shape[1]):\n",
    "    for i in range(clusterAssignments.shape[0]):\n",
    "        if clusterAssignments[i,j]==emptyID:\n",
    "            colours[i,j]='#4422FF'\n",
    "            continue\n",
    "        if np.count_nonzero(clusterAssignments[:,j]==clusterAssignments[i,j])>1:\n",
    "            colours[i,j]='#FF4422'\n",
    "        else:\n",
    "            colours[i,j]='#000000'\n",
    "colours = colours.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace10e60-1302-43d6-8afb-3688f9510174",
   "metadata": {},
   "outputs": [],
   "source": [
    "export_site_occupancy_as_bokehHTML(outputPrefix+'_site_occupancy_filled.html',\n",
    "                                   np.tile( np.arange(nFrames), (nClusts,1) ),\n",
    "                                   clusterAssignments,\n",
    "                                   colours,\n",
    "                                   listClusterDefs=stringSelectionResids,\n",
    "                                   titleText='Final Waters assigned to cluster, using distance cutoff %g Angs.' % distCutoff,\n",
    "                                   bNoteBook=not bPythonScriptExport,\n",
    "                                   palette=bokehPalettes.Viridis256\n",
    "                                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6102d1b8-29f6-48bf-8f46-52f91e646aa8",
   "metadata": {},
   "source": [
    "## Writing Output system\n",
    "Note: Completely empty assignments will remain empty from this stage onwards."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de0970ca-feae-4a33-b624-5daed20a817e",
   "metadata": {},
   "source": [
    "### Convert the solvent indices back to global indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7969391e-5fc8-4dcb-be9c-91b6da9b8abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# = = = Load the positions of all waters at once to save on File-IO\n",
    "# = = = This one is too expensive in terms of getting *every water*\n",
    "if False:\n",
    "    uAllWatersIn = load_subuniverse_inmem(u, seltxtSolv)\n",
    "    atomSelSite  = uAllWatersIn.select_atoms(seltxtSite)\n",
    "    dictGlobalIndex = { a:b for a,b in enumerate(atomSelSite.indices) }\n",
    "    print(\"= = Created subuniverse for all waters.\")\n",
    "    get_memory_use()\n",
    "\n",
    "k = np.array(list(dictGlobalIndex.keys()))\n",
    "v = np.array(list(dictGlobalIndex.values()))\n",
    "mapping_ar = np.zeros(k.max()+1,dtype=v.dtype) #k,v from approach #1\n",
    "mapping_ar[k] = v\n",
    "    \n",
    "clusterAssignmentsOut = mapping_ar[clusterAssignments]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc0aae0-e237-4d46-95c3-84c2b4ee4f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_water_universe(nSol, listNames=['O', 'H', 'H'], resName='SOL', res0=1, segID='SOL', bTraj=False):\n",
    "    nAtoms = nSol*3\n",
    "    resIndices = np.repeat(range(nSol), 3)\n",
    "    segIndices = [0]*nSol\n",
    "    sol = mda.Universe.empty(nAtoms, n_residues=nSol, atom_resindex=resIndices, residue_segindex=segIndices, trajectory=bTraj)\n",
    "    sol.add_TopologyAttr('name', listNames*nSol)\n",
    "    sol.add_TopologyAttr('type', ['O', 'H', 'H']*nSol)\n",
    "    sol.add_TopologyAttr('resname', [resName]*nSol)\n",
    "    sol.add_TopologyAttr('resid', list(range(res0,nSol+res0)))\n",
    "    sol.add_TopologyAttr('segid', [segID])\n",
    "    \n",
    "    bonds = []\n",
    "    for i in range(0, nAtoms, 3):\n",
    "        bonds.extend([(i, i+1), (i, i+2)])\n",
    "    sol.add_TopologyAttr('bonds', bonds)\n",
    "    return sol\n",
    "\n",
    "def create_universe_from_selection(u, atomSel):\n",
    "    \"\"\"\n",
    "    Need an In-memory version in order to write-out the trajectory\n",
    "    \"\"\"\n",
    "    from MDAnalysis.analysis.base import AnalysisFromFunction\n",
    "    xyz = AnalysisFromFunction(lambda ag: ag.positions.copy(),\n",
    "                                   atomSel).run().results\n",
    "    u2 = mda.Merge(atomSel)\n",
    "    u2.load_new(xyz, format=MemoryReader)\n",
    "\n",
    "def get_water_site_positions(mdaU, oxyIDs, emptyID=0):\n",
    "    nSol, nFrames = oxyIDs.shape\n",
    "    posOut=np.zeros( (nFrames,nSol*3,3), dtype=float)\n",
    "    for j in range(nFrames):\n",
    "        mdaU.trajectory[j]\n",
    "        for i in range(nSol):\n",
    "            oxyID = oxyIDs[i,j]\n",
    "            if oxyID > emptyID:\n",
    "                posOut[j,i*3:(i+1)*3,:]=mdaU.select_atoms(\"index %i %i %i\" % (oxyID,oxyID+1,oxyID+2)).positions\n",
    "    return posOut\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "858740b3-3885-43c2-ad4d-431b91cd927d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# = = = Create water universe from positions. This one is too expensive in terms of getting *every water*\n",
    "print( \"= = Creating a pure solvent universe for writing.\")\n",
    "if False:\n",
    "    memReader = MemoryReader(get_water_site_positions(uAllWatersIn, clusterAssignmentsOut),\n",
    "                         dt=u.trajectory.dt)\n",
    "    uWat = create_water_universe(nClusts, listNames=['OW', 'HW1', 'HW2'], res0=0, segID='CRY', bTraj=True)\n",
    "    uWat.trajectory = memReader\n",
    "    uAllWatersIn.trajectory = None\n",
    "else:\n",
    "    memReader = MemoryReader(get_water_site_positions(u, clusterAssignmentsOut),\n",
    "                         dt=u.trajectory.dt)\n",
    "    uWat = create_water_universe(nClusts, listNames=['OW', 'HW1', 'HW2'], res0=0, segID='CRY', bTraj=True)\n",
    "    uWat.trajectory = memReader        \n",
    "\n",
    "print( \"= = Pure solvent universe created.\")\n",
    "get_memory_use()\n",
    "# Use mda.Merge() as needed to write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e2711e-84ff-4fa6-beb5-9c5da2aceef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print( \"= = Writing the output universe to file...\")\n",
    "if bWriteOnlyWaters:\n",
    "    selWatersOut = uWat.select_atoms(\"all\")\n",
    "    selWatersOut.universe.trajectory[0]\n",
    "    selWatersOut.write(outputPrefix+'_solvent.pdb')   \n",
    "    selWatersOut.write(outputPrefix+'_solvent.xtc', frames='all')    \n",
    "else:\n",
    "    # Create a new universe from the combination of the two. \n",
    "    selSoluteIn  = u.select_atoms(seltxtSyst)\n",
    "    selWatersIn  = uWat.select_atoms(\"all\")\n",
    "    uSystemOut   = mda.Merge(selSoluteIn,selWatersIn)\n",
    "    nAtomsSolute = selSoluteIn.n_atoms\n",
    "    nAtomsWater  = selWatersIn.n_atoms\n",
    "    dimSystemOut = (nFrames, uSystemOut.trajectory.n_atoms, 3 )\n",
    "    memReaderOutputSystem = MemoryReader(np.zeros( dimSystemOut, dtype=float ), dt=u.trajectory.dt)\n",
    "    uSystemOut.trajectory = memReaderOutputSystem\n",
    "    \n",
    "    # = = = Transfer positions to the in-memory output system from the source system (which is probably from file)\n",
    "    if False:\n",
    "        uSoluteIn = load_subuniverse_inmem(u, seltxtSyst)\n",
    "        uSystemOut.trajectory.coordinate_array[:,0:nAtomsSolute,:] = uSoluteIn.trajectory.coordinate_array\n",
    "        uSystemOut.trajectory.coordinate_array[:,nAtomsSolute:nAtomsSolute+nAtomsWater,:] = uWat.trajectory.coordinate_array\n",
    "    else:\n",
    "        selSoluteOut = uSystemOut.select_atoms(seltxtSyst)\n",
    "        selWatersOut = uSystemOut.select_atoms(seltxtSolv)\n",
    "        for f in range(uSystemOut.trajectory.n_frames):\n",
    "            u.trajectory[f] ; uWat.trajectory[f] ; uSystemOut.trajectory[f]\n",
    "            selSoluteOut.positions = selSoluteIn.positions\n",
    "            selWatersOut.positions = selWatersIn.positions\n",
    "\n",
    "    selSystemOut = uSystemOut.select_atoms(\"all\")\n",
    "    selSystemOut.universe.trajectory[0]\n",
    "    selSystemOut.write(outputPrefix+'.pdb')\n",
    "    selSystemOut.write(outputPrefix+'.xtc', frames='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9962d84-7922-4144-b373-65b1ece7ea7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print( \"= = Trajectory writing complete. Finishing up.\")\n",
    "get_memory_use()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b65342c2-ae1a-4999-b545-205d5e2de8be",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
